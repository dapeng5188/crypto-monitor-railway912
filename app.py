#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ å¯†è´§å¸å½¢æ€è¯†åˆ«ç›‘æ§ç³»ç»Ÿ - ä¿®å¤ç‰ˆ

æœ¬ç³»ç»Ÿä¸“æ³¨äºè¯†åˆ«å››ç§ç»å…¸çš„ä»·æ ¼å½¢æ€ï¼šåŒé¡¶ã€åŒåº•ã€EMAè¶‹åŠ¿ã€‚
é‡‡ç”¨å¤šæ•°æ®æºæ¶æ„ï¼Œå…·å¤‡è‡ªåŠ¨æ•…éšœè½¬ç§»èƒ½åŠ›ï¼Œé€šè¿‡ä¸¥æ ¼çš„æŠ€æœ¯æŒ‡æ ‡éªŒè¯ç¡®ä¿ä¿¡å·è´¨é‡ã€‚

ä¸»è¦ç‰¹æ€§ï¼š
- æ™ºèƒ½ç¼“å­˜ç®¡ç†ï¼Œä»…ç¼“å­˜æå€¼ç‚¹å’Œå¿…è¦æ•°æ®
- å¹¶å‘å¤„ç†æå‡æ€§èƒ½
- 14å‘¨æœŸATRåŠ¨æ€è®¡ç®—
- ç²¾ç¡®çš„ABCç‚¹è·å–é€»è¾‘
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–å’Œè‡ªåŠ¨æ¸…ç†
"""

import os
import sys
import time
import json
import logging
import requests
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from flask import Flask, jsonify, render_template_string
import schedule
from concurrent.futures import ThreadPoolExecutor, as_completed
import numpy as np
from dataclasses import dataclass
import gc
import psutil
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import mplfinance as mpf
from PIL import Image
import io
import base64
from telegram import Bot
from telegram.error import TelegramError
import asyncio
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿— - ä¼˜åŒ–Railwayç¯å¢ƒæ”¯æŒ
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®ï¼Œä¼˜åŒ–Railwayç¯å¢ƒæ”¯æŒ"""
    # æ£€æµ‹æ˜¯å¦åœ¨Railwayç¯å¢ƒ
    is_railway = os.environ.get('RAILWAY_ENVIRONMENT') is not None or os.environ.get('PORT') is not None
    
    handlers = []
    
    # æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨
    try:
        file_handler = logging.FileHandler('realtime_monitor.log', encoding='utf-8')
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        handlers.append(file_handler)
    except Exception as e:
        print(f"æ— æ³•åˆ›å»ºæ–‡ä»¶æ—¥å¿—å¤„ç†å™¨: {e}")
    
    # æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    handlers.append(console_handler)
    
    # Railwayç¯å¢ƒç‰¹æ®Šé…ç½®
    if is_railway:
        # ç¡®ä¿æ—¥å¿—ç«‹å³åˆ·æ–°åˆ°stdout
        console_handler.setLevel(logging.INFO)
        # æ·»åŠ é¢å¤–çš„stderrå¤„ç†å™¨ä»¥ç¡®ä¿é”™è¯¯æ—¥å¿—å¯è§
        stderr_handler = logging.StreamHandler(sys.stderr)
        stderr_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        stderr_handler.setLevel(logging.WARNING)
        handlers.append(stderr_handler)
    
    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers,
        force=True  # å¼ºåˆ¶é‡æ–°é…ç½®
    )
    
    # è®¾ç½®ç‰¹å®šåº“çš„æ—¥å¿—çº§åˆ«
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('requests').setLevel(logging.WARNING)
    
    return logging.getLogger(__name__)

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_logging()

# Railwayç¯å¢ƒæ£€æµ‹æ—¥å¿—
if os.environ.get('RAILWAY_ENVIRONMENT') or os.environ.get('PORT'):
    logger.info("æ£€æµ‹åˆ°Railwayéƒ¨ç½²ç¯å¢ƒï¼Œå·²ä¼˜åŒ–æ—¥å¿—é…ç½®")
else:
    logger.info("æœ¬åœ°å¼€å‘ç¯å¢ƒï¼Œä½¿ç”¨æ ‡å‡†æ—¥å¿—é…ç½®")

@dataclass
class ExtremePoint:
    """æå€¼ç‚¹æ•°æ®ç»“æ„"""
    timestamp: int
    price: float
    point_type: str  # 'high' or 'low'

@dataclass
class PatternCache:
    """å½¢æ€ç¼“å­˜æ•°æ®ç»“æ„"""
    a_point: Optional[ExtremePoint] = None
    d_point: Optional[ExtremePoint] = None  # å¤´è‚©å½¢æ€çš„å·¦è‚©ç‚¹
    last_update: Optional[datetime] = None
    atr_value: Optional[float] = None
    atr_timestamp: Optional[int] = None

class DataCache:
    """æ•°æ®ç¼“å­˜ç®¡ç†ç±»"""
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 300):
        self.kline_cache = {}
        self.extreme_cache = {}
        self.atr_cache = {}
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self._access_times = {}
        
    def get_klines(self, symbol: str, timeframe: str, limit: int = 55) -> Optional[List[List]]:
        """è·å–Kçº¿æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{symbol}_{timeframe}_{limit}"
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
        if cache_key in self.kline_cache:
            cached_data, timestamp = self.kline_cache[cache_key]
            if current_time - timestamp < self.ttl_seconds:
                self._access_times[cache_key] = current_time
                return cached_data
        
        return None
    
    def set_klines(self, symbol: str, timeframe: str, data: List[List], limit: int = 55):
        """ç¼“å­˜Kçº¿æ•°æ®"""
        cache_key = f"{symbol}_{timeframe}_{limit}"
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œå¿…è¦æ—¶æ¸…ç†
        if len(self.kline_cache) >= self.max_size:
            self._cleanup_cache()
        
        self.kline_cache[cache_key] = (data, current_time)
        self._access_times[cache_key] = current_time
    
    def get_atr(self, symbol: str, timeframe: str) -> Optional[float]:
        """è·å–ATRå€¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{symbol}_{timeframe}_atr"
        current_time = time.time()
        
        if cache_key in self.atr_cache:
            atr_value, timestamp = self.atr_cache[cache_key]
            if current_time - timestamp < self.ttl_seconds:
                return atr_value
        
        return None
    
    def set_atr(self, symbol: str, timeframe: str, atr_value: float):
        """ç¼“å­˜ATRå€¼"""
        cache_key = f"{symbol}_{timeframe}_atr"
        current_time = time.time()
        self.atr_cache[cache_key] = (atr_value, current_time)
    
    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸå’Œæœ€å°‘ä½¿ç”¨çš„ç¼“å­˜"""
        current_time = time.time()
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        expired_keys = []
        for key, (data, timestamp) in self.kline_cache.items():
            if current_time - timestamp > self.ttl_seconds:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.kline_cache[key]
            if key in self._access_times:
                del self._access_times[key]
        
        # å¦‚æœä»ç„¶è¶…è¿‡å¤§å°é™åˆ¶ï¼Œåˆ é™¤æœ€å°‘ä½¿ç”¨çš„ç¼“å­˜
        if len(self.kline_cache) >= self.max_size:
            # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€è€çš„
            sorted_keys = sorted(self._access_times.items(), key=lambda x: x[1])
            keys_to_remove = [k for k, _ in sorted_keys[:self.max_size // 4]]  # åˆ é™¤25%
            
            for key in keys_to_remove:
                if key in self.kline_cache:
                    del self.kline_cache[key]
                if key in self._access_times:
                    del self._access_times[key]
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
    
    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.kline_cache.clear()
        self.extreme_cache.clear()
        self.atr_cache.clear()
        self._access_times.clear()
        gc.collect()

class CryptoPatternMonitor:
    """åŠ å¯†è´§å¸å½¢æ€è¯†åˆ«ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
        self.running = False
        self.pattern_cache = {}  # ç»Ÿä¸€çš„å½¢æ€ç¼“å­˜
        self.last_analysis_time = {}  # æœ€ååˆ†ææ—¶é—´ï¼ˆé˜²é‡å¤åˆ†æï¼‰
        self.last_webhook_time = 0  # å…¨å±€webhookå‘é€æ—¶é—´æ§åˆ¶
        self.sent_signals = {}  # å·²å‘é€ä¿¡å·è®°å½• {signal_key: timestamp}
        self.api_sources = self._init_api_sources()
        self.current_api_index = 0
        self.monitored_pairs = self._get_monitored_pairs()
        self.timeframes = ['1h']  # åªç›‘æ§1å°æ—¶æ—¶é—´ç²’åº¦
        self.webhook_url = "https://n8n-ayzvkyda.ap-northeast-1.clawcloudrun.com/webhook-test/double_t_b"
        
        # Telegramé…ç½®
        self.telegram_token = os.environ.get('TELEGRAM_BOT_TOKEN', '')
        self.telegram_channel_id = os.environ.get('TELEGRAM_CHANNEL_ID', '')
        
        # è¯¦ç»†çš„Telegramé…ç½®è°ƒè¯•ä¿¡æ¯
        logger.info(f"ğŸ” Telegramé…ç½®æ£€æŸ¥:")
        logger.info(f"  - Tokenå­˜åœ¨: {'æ˜¯' if self.telegram_token else 'å¦'}")
        logger.info(f"  - Tokené•¿åº¦: {len(self.telegram_token) if self.telegram_token else 0}")
        logger.info(f"  - Channel IDå­˜åœ¨: {'æ˜¯' if self.telegram_channel_id else 'å¦'}")
        logger.info(f"  - Channel ID: {self.telegram_channel_id}")
        
        # æµ‹è¯•ç¯å¢ƒå˜é‡è¯»å–
        logger.info(f"ğŸ”§ ç¯å¢ƒå˜é‡æµ‹è¯•:")
        all_env_vars = dict(os.environ)
        telegram_vars = {k: v for k, v in all_env_vars.items() if 'TELEGRAM' in k.upper()}
        if telegram_vars:
            logger.info(f"  - æ‰¾åˆ°Telegramç›¸å…³ç¯å¢ƒå˜é‡: {list(telegram_vars.keys())}")
            for key, value in telegram_vars.items():
                # åªæ˜¾ç¤ºå‰10ä¸ªå­—ç¬¦ï¼Œä¿æŠ¤æ•æ„Ÿä¿¡æ¯
                masked_value = value[:10] + '...' if len(value) > 10 else value
                logger.info(f"  - {key}: {masked_value}")
        else:
            logger.warning(f"  - æœªæ‰¾åˆ°ä»»ä½•Telegramç›¸å…³ç¯å¢ƒå˜é‡")
            logger.info(f"  - å½“å‰æ‰€æœ‰ç¯å¢ƒå˜é‡æ•°é‡: {len(all_env_vars)}")
            # æ˜¾ç¤ºéƒ¨åˆ†ç¯å¢ƒå˜é‡åç§°ç”¨äºè°ƒè¯•
            env_keys = list(all_env_vars.keys())[:10]
            logger.info(f"  - å‰10ä¸ªç¯å¢ƒå˜é‡: {env_keys}")
        
        # å°è¯•åˆ›å»ºTelegram Botå®ä¾‹ï¼ˆä¼˜åŒ–è¿æ¥æ± é…ç½®ï¼‰
        self.telegram_bot = None
        if self.telegram_token:
            try:
                from telegram.request import HTTPXRequest
                
                # åˆ›å»ºè‡ªå®šä¹‰HTTPè¯·æ±‚é…ç½®ï¼Œè§£å†³è¿æ¥æ± è¶…æ—¶é—®é¢˜
                request = HTTPXRequest(
                    connection_pool_size=20,  # å¢åŠ è¿æ¥æ± å¤§å°
                    pool_timeout=60.0,        # å¢åŠ æ± è¶…æ—¶æ—¶é—´
                    connect_timeout=30.0,     # è¿æ¥è¶…æ—¶
                    read_timeout=30.0,        # è¯»å–è¶…æ—¶
                    write_timeout=30.0,       # å†™å…¥è¶…æ—¶
                )
                
                self.telegram_bot = Bot(token=self.telegram_token, request=request)
                logger.info("âœ… Telegram Botå®ä¾‹åˆ›å»ºæˆåŠŸï¼ˆå·²ä¼˜åŒ–è¿æ¥æ± é…ç½®ï¼‰")
                
                # æµ‹è¯•Botè¿æ¥ï¼ˆå¼‚æ­¥è°ƒç”¨éœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œï¼‰
                try:
                    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥æ‰§è¡Œå¼‚æ­¥æ“ä½œ
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        bot_info = loop.run_until_complete(self.telegram_bot.get_me())
                        logger.info(f"âœ… Botè¿æ¥æµ‹è¯•æˆåŠŸ: @{bot_info.username}")
                    finally:
                        loop.close()
                except Exception as test_error:
                    logger.error(f"âŒ Botè¿æ¥æµ‹è¯•å¤±è´¥: {str(test_error)}")
                    
            except Exception as bot_error:
                logger.error(f"âŒ Telegram Botå®ä¾‹åˆ›å»ºå¤±è´¥: {str(bot_error)}")
                self.telegram_bot = None
        else:
            logger.warning("âŒ Telegram Botå®ä¾‹åˆ›å»ºå¤±è´¥ - Tokenä¸ºç©º")
            
        self.last_telegram_time = 0  # Telegramå‘é€æ—¶é—´æ§åˆ¶
        self.telegram_send_interval = 3  # 3ç§’é—´éš”
        
        # æ•°æ®ç¼“å­˜ç³»ç»Ÿ
        self.data_cache = DataCache(max_size=500, ttl_seconds=240)  # 4åˆ†é’Ÿç¼“å­˜
        
        # æ€§èƒ½é…ç½®
        self.max_concurrent_analysis = 15  # å¢åŠ å¹¶å‘æ•°
        self.analysis_timeout = 30
        self.memory_limit = 300 * 1024 * 1024  # 300MB
        
        # ç³»ç»Ÿå¥åº·çŠ¶æ€è·Ÿè¸ª
        self.system_health = {
            'status': 'healthy',
            'start_time': datetime.now(),
            'last_heartbeat': datetime.now(),
            'error_count': 0,
            'consecutive_errors': 0,
            'last_error_time': None,
            'recovery_attempts': 0,
            'max_recovery_attempts': 3  # å‡å°‘æœ€å¤§æ¢å¤å°è¯•æ¬¡æ•°
        }
        
        # ç›‘æ§çº¿ç¨‹çŠ¶æ€
        self.monitor_threads = {}
        self.thread_health = {}
        
        # å¼‚å¸¸æ¢å¤é…ç½®
        self.recovery_config = {
            'max_consecutive_errors': 15,  # å¢åŠ å®¹é”™æ€§
            'recovery_delay': [60, 120, 300],  # å‡å°‘æ¢å¤å»¶è¿Ÿå±‚çº§
            'health_check_interval': 120,  # å¢åŠ å¥åº·æ£€æŸ¥é—´éš”
            'auto_restart_threshold': 25  # æé«˜è‡ªåŠ¨é‡å¯é˜ˆå€¼
        }
        
        logger.info("åŠ å¯†è´§å¸å½¢æ€è¯†åˆ«ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _update_system_health(self, status: str = 'healthy', error: Exception = None):
        """æ›´æ–°ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        try:
            self.system_health['last_heartbeat'] = datetime.now()
            
            if status == 'error' and error:
                self.system_health['error_count'] += 1
                self.system_health['consecutive_errors'] += 1
                self.system_health['last_error_time'] = datetime.now()
                
                if self.system_health['consecutive_errors'] < 8:
                    self.system_health['status'] = 'degraded'
                else:
                    self.system_health['status'] = 'critical'
                    
                logger.error(f"ç³»ç»Ÿå¥åº·çŠ¶æ€æ›´æ–°: {status}, è¿ç»­é”™è¯¯: {self.system_health['consecutive_errors']}, é”™è¯¯: {str(error)}")
            elif status == 'healthy':
                self.system_health['consecutive_errors'] = 0
                self.system_health['status'] = 'healthy'
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ¢å¤
            if self.system_health['consecutive_errors'] >= self.recovery_config['max_consecutive_errors']:
                self._attempt_system_recovery()
                
        except Exception as e:
            logger.error(f"æ›´æ–°ç³»ç»Ÿå¥åº·çŠ¶æ€å¤±è´¥: {str(e)}")
    
    def _attempt_system_recovery(self):
        """å°è¯•ç³»ç»Ÿè‡ªåŠ¨æ¢å¤"""
        try:
            if self.system_health['recovery_attempts'] >= self.system_health['max_recovery_attempts']:
                logger.critical("ç³»ç»Ÿæ¢å¤å°è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œéœ€è¦äººå·¥å¹²é¢„")
                return False
            
            self.system_health['recovery_attempts'] += 1
            recovery_delay = self.recovery_config['recovery_delay']
            delay_index = min(self.system_health['recovery_attempts'] - 1, len(recovery_delay) - 1)
            delay_time = recovery_delay[delay_index]
            
            logger.warning(f"å¼€å§‹ç³»ç»Ÿæ¢å¤å°è¯• {self.system_health['recovery_attempts']}/{self.system_health['max_recovery_attempts']}, å»¶è¿Ÿ {delay_time} ç§’")
            
            # æ¸…ç†ç¼“å­˜å’ŒçŠ¶æ€
            self._cleanup_system_state()
            
            # ç­‰å¾…æ¢å¤å»¶è¿Ÿ
            time.sleep(delay_time)
            
            # é‡æ–°åˆå§‹åŒ–APIæº
            self.api_sources = self._init_api_sources()
            self.current_api_index = 0
            
            logger.info(f"ç³»ç»Ÿæ¢å¤å°è¯• {self.system_health['recovery_attempts']} å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿæ¢å¤å¤±è´¥: {str(e)}")
            return False
    
    def _cleanup_system_state(self):
        """æ¸…ç†ç³»ç»ŸçŠ¶æ€"""
        try:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            self.pattern_cache.clear()
            self.data_cache.clear_all()
            
            # é‡ç½®é”™è¯¯è®¡æ•°
            self.system_health['consecutive_errors'] = max(0, self.system_health['consecutive_errors'] - 5)
            self.system_health['status'] = 'recovering'
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            logger.info("ç³»ç»ŸçŠ¶æ€æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"ç³»ç»ŸçŠ¶æ€æ¸…ç†å¤±è´¥: {str(e)}")
    
    def _check_thread_health(self):
        """æ£€æŸ¥ç›‘æ§çº¿ç¨‹å¥åº·çŠ¶æ€"""
        try:
            current_time = datetime.now()
            for timeframe in self.timeframes:
                thread = self.monitor_threads.get(timeframe)
                health = self.thread_health.get(timeframe, {})
                
                if not thread or not thread.is_alive():
                    logger.warning(f"ç›‘æ§çº¿ç¨‹ {timeframe} å·²åœæ­¢ï¼Œå°è¯•é‡å¯")
                    self._restart_single_monitor(timeframe)
                elif health.get('last_activity'):
                    inactive_time = (current_time - health['last_activity']).total_seconds()
                    # å¢åŠ æ— å“åº”é˜ˆå€¼ï¼Œé¿å…è¯¯åˆ¤
                    if inactive_time > 900:  # 15åˆ†é’Ÿæ— æ´»åŠ¨
                        logger.warning(f"ç›‘æ§çº¿ç¨‹ {timeframe} æ— å“åº” {inactive_time:.0f} ç§’ï¼Œå°è¯•é‡å¯")
                        self._restart_single_monitor(timeframe)
        except Exception as e:
            logger.error(f"çº¿ç¨‹å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
    
    def _restart_single_monitor(self, timeframe: str):
        """é‡å¯å•ä¸ªç›‘æ§çº¿ç¨‹"""
        try:
            # åœæ­¢æ—§çº¿ç¨‹
            old_thread = self.monitor_threads.get(timeframe)
            if old_thread and old_thread.is_alive():
                old_thread.join(timeout=10)
            
            # å¯åŠ¨æ–°çº¿ç¨‹
            new_thread = threading.Thread(target=self._monitor_timeframe, args=(timeframe,), daemon=True)
            new_thread.start()
            self.monitor_threads[timeframe] = new_thread
            self.thread_health[timeframe] = {
                'status': 'running',
                'last_activity': datetime.now(),
                'error_count': 0
            }
            logger.info(f"ç›‘æ§çº¿ç¨‹ {timeframe} é‡å¯æˆåŠŸ")
        except Exception as e:
            logger.error(f"é‡å¯ç›‘æ§çº¿ç¨‹ {timeframe} å¤±è´¥: {str(e)}")
    
    def _init_api_sources(self) -> List[Dict[str, Any]]:
        """åˆå§‹åŒ–APIæ•°æ®æºé…ç½®"""
        return [
            {
                'name': 'Binance',
                'base_url': 'https://api.binance.com/api/v3',
                'klines_endpoint': '/klines',
                'timeout': 15,
                'rate_limit': 1200,
                'requires_key': True
            },
            {
                'name': 'OKX',
                'base_url': 'https://www.okx.com/api/v5',
                'klines_endpoint': '/market/candles',
                'timeout': 10,
                'rate_limit': 600,
                'requires_key': True
            }
        ]
    
    def _get_monitored_pairs(self) -> List[str]:
        """è·å–ç›‘æ§çš„äº¤æ˜“å¯¹åˆ—è¡¨"""
        # é»‘åå•
        blacklist = ['USDCUSDT', 'TUSDUSDT', 'BUSDUSDT', 'FDUSDT']
        
        pairs = [
    'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT',
    'DOGEUSDT', 'ADAUSDT', 'TRXUSDT', 'AVAXUSDT', 'TONUSDT',
    'LINKUSDT', 'DOTUSDT', 'POLUSDT', 'ICPUSDT', 'NEARUSDT',
    'UNIUSDT', 'LTCUSDT', 'APTUSDT', 'FILUSDT', 'ETCUSDT',
    'ATOMUSDT', 'HBARUSDT', 'BCHUSDT', 'INJUSDT', 'SUIUSDT',
    'ARBUSDT', 'OPUSDT', 'FUSDT', 'IMXUSDT', 'STRKUSDT',
    'MANAUSDT', 'VETUSDT', 'ALGOUSDT', 'GRTUSDT', 'SANDUSDT',
    'AXSUSDT', 'FLOWUSDT', 'THETAUSDT', 'CHZUSDT', 'APEUSDT',
    'MKRUSDT', 'AAVEUSDT', 'SNXUSDT', 'QNTUSDT',
    'GALAUSDT', 'ROSEUSDT', 'PLAYUSDT', 'ENJUSDT', 'RUNEUSDT',
    'WIFUSDT', 'BONKUSDT', 'FLOKIUSDT', 'NOTUSDT',
    'PEOPLEUSDT', 'JUPUSDT', 'WLDUSDT', 'ORDIUSDT', 'SEIUSDT',
    'TIAUSDT', 'RENDERUSDT', 'FETUSDT', 'ARKMUSDT',
    'PENGUUSDT', 'PNUTUSDT', 'ACTUSDT', 'NEIROUSDT',
    'RAYUSDT', 'BOMEUSDT', 'MEMEUSDT', 'MOVEUSDT',
    'EIGENUSDT', 'DYDXUSDT', 'TURBOUSDT','PYTHUSDT', 'JASMYUSDT', 'COMPUSDT', 'CRVUSDT', 'LRCUSDT',
    'SUSHIUSDT', 'SUSDT', 'YGGUSDT', 'CAKEUSDT', 'OGUSDT',
    'STORJUSDT', 'KNCUSDT', 'RIVERUSDT', 'YFIUSDT', 'FORMUSDT',
    'ZRXUSDT', 'XLMUSDT', 'XMRUSDT', 'XTZUSDT','BAKEUSDT',
     'DOLOUSDT', 'SOMIUSDT', 'TRUMPUSDT', 'ONDOUSDT',
    'NMRUSDT', 'BBUSDT',  'ZECUSDT'
]
        
        # è¿‡æ»¤é»‘åå•
        filtered_pairs = [pair for pair in pairs if pair not in blacklist]
        logger.info(f"ç›‘æ§äº¤æ˜“å¯¹æ•°é‡: {len(filtered_pairs)}")
        return filtered_pairs
    
    def _get_klines_data(self, symbol: str, interval: str, limit: int = 100) -> Optional[List[List]]:
        """è·å–Kçº¿æ•°æ®ï¼Œæ”¯æŒç¼“å­˜å’ŒAPIè½®æ¢"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        cached_data = self.data_cache.get_klines(symbol, interval, limit)
        if cached_data:
            return cached_data
        
        max_retries = len(self.api_sources) * 2
        retry_delays = [1, 2, 3, 5, 8]
        
        for attempt in range(max_retries):
            api_source = self.api_sources[self.current_api_index]
            delay = retry_delays[min(attempt, len(retry_delays) - 1)]
            
            try:
                if api_source['name'] == 'Binance':
                    url = f"{api_source['base_url']}{api_source['klines_endpoint']}"
                    params = {
                        'symbol': symbol,
                        'interval': interval,
                        'limit': limit
                    }
                    
                    response = requests.get(
                        url, 
                        params=params, 
                        timeout=api_source.get('timeout', 15),
                        headers={'User-Agent': 'CryptoPatternMonitor/2.0'}
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        
                        if not data or not isinstance(data, list) or len(data) == 0:
                            raise ValueError("Binance APIè¿”å›ç©ºæ•°æ®æˆ–æ ¼å¼é”™è¯¯")
                        
                        if len(data[0]) < 6:
                            raise ValueError("Binance Kçº¿æ•°æ®æ ¼å¼ä¸å®Œæ•´")
                        
                        validated_data = []
                        for kline in data:
                            try:
                                validated_kline = [float(x) for x in kline[:6]]
                                if validated_kline[2] < validated_kline[3]:
                                    logger.warning(f"è·³è¿‡å¼‚å¸¸Kçº¿æ•°æ®: high({validated_kline[2]}) < low({validated_kline[3]})")
                                    continue
                                validated_data.append(validated_kline)
                            except (ValueError, IndexError):
                                continue
                        
                        if len(validated_data) >= limit * 0.8:
                            # ç¼“å­˜æ•°æ®
                            self.data_cache.set_klines(symbol, interval, validated_data, limit)
                            return validated_data
                        else:
                            raise ValueError(f"æœ‰æ•ˆæ•°æ®ä¸è¶³: {len(validated_data)}/{limit}")
                    
                    elif response.status_code == 429:
                        logger.warning(f"{api_source['name']} APIé™æµï¼Œå»¶é•¿ç­‰å¾…æ—¶é—´")
                        time.sleep(delay * 2)
                        continue
                    else:
                        logger.warning(f"{api_source['name']} APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                
                elif api_source['name'] == 'OKX':
                    url = f"{api_source['base_url']}{api_source['klines_endpoint']}"
                    okx_symbol = symbol.replace('USDT', '-USDT') if 'USDT' in symbol else symbol
                    
                    # OKX APIæ—¶é—´é—´éš”æ˜ å°„
                    interval_map = {
                        '1m': '1m', '3m': '3m', '5m': '5m', '15m': '15m', '30m': '30m',
                        '1h': '1H', '2h': '2H', '4h': '4H', '6h': '6H', '8h': '8H', '12h': '12H',
                        '1d': '1D', '3d': '3D', '1w': '1W', '1M': '1M', '3M': '3M'
                    }
                    okx_interval = interval_map.get(interval, interval)
                    
                    params = {
                        'instId': okx_symbol,
                        'bar': okx_interval,
                        'limit': str(limit)
                    }
                    
                    response = requests.get(
                        url, 
                        params=params, 
                        timeout=api_source.get('timeout', 15),
                        headers={'User-Agent': 'CryptoPatternMonitor/2.0'}
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        
                        if data.get('code') == '0' and data.get('data'):
                            okx_data = data['data']
                            
                            if not okx_data or len(okx_data) == 0:
                                raise ValueError("OKX APIè¿”å›ç©ºæ•°æ®")
                            
                            validated_data = []
                            for kline in okx_data:
                                try:
                                    if len(kline) < 6:
                                        continue
                                    validated_kline = [float(x) for x in kline[:6]]
                                    if validated_kline[2] < validated_kline[3]:
                                        continue
                                    validated_data.append(validated_kline)
                                except (ValueError, IndexError):
                                    continue
                            
                            if len(validated_data) >= limit * 0.8:
                                # ç¼“å­˜æ•°æ®
                                self.data_cache.set_klines(symbol, interval, validated_data, limit)
                                return validated_data
                            else:
                                raise ValueError(f"æœ‰æ•ˆæ•°æ®ä¸è¶³: {len(validated_data)}/{limit}")
                        else:
                            raise ValueError(f"OKX APIé”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                
            except requests.exceptions.Timeout:
                logger.warning(f"{api_source['name']} APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            except requests.exceptions.ConnectionError:
                logger.warning(f"{api_source['name']} APIè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries})")
            except Exception as e:
                logger.warning(f"{api_source['name']} APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
            
            # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPIæº
            if (attempt + 1) % 2 == 0:
                old_index = self.current_api_index
                self.current_api_index = (self.current_api_index + 1) % len(self.api_sources)
                logger.info(f"åˆ‡æ¢APIæº: {self.api_sources[old_index]['name']} -> {self.api_sources[self.current_api_index]['name']}")
            
            if attempt < max_retries - 1:
                time.sleep(delay)
        
        logger.error(f"æ‰€æœ‰APIæºéƒ½å¤±è´¥ï¼Œæ— æ³•è·å– {symbol} çš„Kçº¿æ•°æ®")
        return None
    
    def _detect_extreme_points(self, klines: List[List]) -> List[ExtremePoint]:
        """æ£€æµ‹æå€¼ç‚¹"""
        if len(klines) < 3:
            return []
        
        extreme_points = []
        
        for i in range(1, len(klines) - 1):
            current = klines[i]
            prev = klines[i - 1]
            next_kline = klines[i + 1]
            
            timestamp = int(current[0])
            high = float(current[2])  # ç¡®ä¿ä¸ºæµ®ç‚¹æ•°
            low = float(current[3])   # ç¡®ä¿ä¸ºæµ®ç‚¹æ•°
            
            # æ£€æµ‹é«˜ç‚¹
            if high > float(prev[2]) and high > float(next_kline[2]):
                extreme_points.append(ExtremePoint(
                    timestamp=timestamp,
                    price=high,
                    point_type='high'
                ))
            
            # æ£€æµ‹ä½ç‚¹
            if low < float(prev[3]) and low < float(next_kline[3]):
                extreme_points.append(ExtremePoint(
                    timestamp=timestamp,
                    price=low,
                    point_type='low'
                ))
        
        return extreme_points
    
    def _initialize_all_pattern_cache(self):
        """å¯åŠ¨æ—¶åˆå§‹åŒ–æ‰€æœ‰ä»£å¸çš„Aç‚¹ç¼“å­˜"""
        try:
            symbols = self._get_monitored_pairs()
            logger.info(f"å¼€å§‹ä¸º {len(symbols)} ä¸ªä»£å¸åˆå§‹åŒ–Aç‚¹ç¼“å­˜")
            
            for symbol in symbols:
                for timeframe in self.timeframes:
                    try:
                        self._initialize_pattern_cache(symbol, timeframe)
                        logger.debug(f"åˆå§‹åŒ– {symbol}_{timeframe} Aç‚¹ç¼“å­˜å®Œæˆ")
                    except Exception as e:
                        logger.error(f"åˆå§‹åŒ– {symbol}_{timeframe} Aç‚¹ç¼“å­˜å¤±è´¥: {str(e)}")
                        continue
            
            logger.info("æ‰€æœ‰ä»£å¸Aç‚¹ç¼“å­˜åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ‰€æœ‰ä»£å¸Aç‚¹ç¼“å­˜å¤±è´¥: {str(e)}")
    
    def _initialize_pattern_cache(self, symbol: str, timeframe: str):
        """åˆå§‹åŒ–å½¢æ€ç¼“å­˜åŒº"""
        cache_key = f"{symbol}_{timeframe}"
        
        if cache_key in self.pattern_cache:
            return
        
        # è·å–è¶³å¤Ÿçš„å†å²Kçº¿æ•°æ®
        klines = self._get_klines_data(symbol, timeframe, 55)
        if not klines or len(klines) < 55:
            logger.error(f"æ— æ³•åˆå§‹åŒ– {cache_key} çš„å½¢æ€ç¼“å­˜")
            return
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.pattern_cache[cache_key] = {
            'double_top': PatternCache(),
            'double_bottom': PatternCache(),
            'head_shoulders_top': PatternCache(),
            'head_shoulders_bottom': PatternCache()
        }
        
        # æ›´æ–°ç¼“å­˜æ•°æ®
        self._update_pattern_cache(symbol, timeframe, klines)
        
        logger.info(f"åˆå§‹åŒ– {cache_key} å½¢æ€ç¼“å­˜å®Œæˆ")
    
    def _update_pattern_cache(self, symbol: str, timeframe: str, klines: List[List] = None):
        """æ›´æ–°å½¢æ€ç¼“å­˜åŒº"""
        cache_key = f"{symbol}_{timeframe}"
        
        if klines is None:
            klines = self._get_klines_data(symbol, timeframe, 55)
        
        if not klines or len(klines) < 55:
            return
        
        if cache_key not in self.pattern_cache:
            self.pattern_cache[cache_key] = {
                'double_top': PatternCache(),
                'double_bottom': PatternCache(),
                'head_shoulders_top': PatternCache(),
                'head_shoulders_bottom': PatternCache()
            }
        
        current_time = datetime.now()
        
        # Aç‚¹åŒºé—´ï¼šç¬¬13-34æ ¹Kçº¿
        a_range_klines = klines[-34:-13]
        # Dç‚¹åŒºé—´ï¼šç¬¬35-55æ ¹Kçº¿ï¼ˆç”¨äºå¤´è‚©å½¢æ€ï¼‰
        d_range_klines = klines[-55:-35]
        
        if len(a_range_klines) < 20 or len(d_range_klines) < 18:
            return
        
        # æ›´æ–°åŒé¡¶ç¼“å­˜
        cache = self.pattern_cache[cache_key]['double_top']
        if not cache.a_point or self._is_point_expired(cache.a_point, klines):
            # æ‰¾Aç‚¹åŒºé—´æœ€é«˜ç‚¹
            max_high = float('-inf')
            max_high_timestamp = None
            for kline in a_range_klines:
                if float(kline[2]) > max_high:
                    max_high = float(kline[2])  # ä¿®å¤ï¼šç¡®ä¿ä»·æ ¼ä¸ºæµ®ç‚¹æ•°
                    max_high_timestamp = int(kline[0])
            
            cache.a_point = ExtremePoint(max_high_timestamp, max_high, 'high')
            cache.last_update = current_time
        
        # æ›´æ–°åŒåº•ç¼“å­˜
        cache = self.pattern_cache[cache_key]['double_bottom']
        if not cache.a_point or self._is_point_expired(cache.a_point, klines):
            # æ‰¾Aç‚¹åŒºé—´æœ€ä½ç‚¹
            min_low = float('inf')
            min_low_timestamp = None
            for kline in a_range_klines:
                if float(kline[3]) < min_low:
                    min_low = float(kline[3])  # ä¿®å¤ï¼šç¡®ä¿ä»·æ ¼ä¸ºæµ®ç‚¹æ•°
                    min_low_timestamp = int(kline[0])
            
            cache.a_point = ExtremePoint(min_low_timestamp, min_low, 'low')
            cache.last_update = current_time
        
        # æ›´æ–°å¤´è‚©é¡¶ç¼“å­˜
        cache = self.pattern_cache[cache_key]['head_shoulders_top']
        if not cache.a_point or self._is_point_expired(cache.a_point, klines):
            # æ‰¾Aç‚¹åŒºé—´æœ€é«˜ç‚¹
            max_high = float('-inf')
            max_high_timestamp = None
            for kline in a_range_klines:
                if float(kline[2]) > max_high:
                    max_high = float(kline[2])  # ä¿®å¤ï¼šç¡®ä¿ä»·æ ¼ä¸ºæµ®ç‚¹æ•°
                    max_high_timestamp = int(kline[0])
            
            cache.a_point = ExtremePoint(max_high_timestamp, max_high, 'high')
            cache.last_update = current_time
        
        if not cache.d_point or self._is_point_expired(cache.d_point, klines):
            # æ‰¾Dç‚¹åŒºé—´æœ€é«˜ç‚¹ï¼ˆå·¦è‚©ï¼‰
            max_high_d = float('-inf')
            max_high_d_timestamp = None
            for kline in d_range_klines:
                if float(kline[2]) > max_high_d:
                    max_high_d = float(kline[2])  # ä¿®å¤ï¼šç¡®ä¿ä»·æ ¼ä¸ºæµ®ç‚¹æ•°
                    max_high_d_timestamp = int(kline[0])
            
            cache.d_point = ExtremePoint(max_high_d_timestamp, max_high_d, 'high')
        
        # æ›´æ–°å¤´è‚©åº•ç¼“å­˜
        cache = self.pattern_cache[cache_key]['head_shoulders_bottom']
        if not cache.a_point or self._is_point_expired(cache.a_point, klines):
            # æ‰¾Aç‚¹åŒºé—´æœ€ä½ç‚¹
            min_low = float('inf')
            min_low_timestamp = None
            for kline in a_range_klines:
                if float(kline[3]) < min_low:
                    min_low = float(kline[3])  # ä¿®å¤ï¼šç¡®ä¿ä»·æ ¼ä¸ºæµ®ç‚¹æ•°
                    min_low_timestamp = int(kline[0])
            
            cache.a_point = ExtremePoint(min_low_timestamp, min_low, 'low')
            cache.last_update = current_time
        
        if not cache.d_point or self._is_point_expired(cache.d_point, klines):
            # æ‰¾Dç‚¹åŒºé—´æœ€ä½ç‚¹ï¼ˆå·¦è‚©ï¼‰
            min_low_d = float('inf')
            min_low_d_timestamp = None
            for kline in d_range_klines:
                if float(kline[3]) < min_low_d:
                    min_low_d = float(kline[3])  # ä¿®å¤ï¼šç¡®ä¿ä»·æ ¼ä¸ºæµ®ç‚¹æ•°
                    min_low_d_timestamp = int(kline[0])
            
            cache.d_point = ExtremePoint(min_low_d_timestamp, min_low_d, 'low')
    
    def _check_and_update_a_points(self, symbol: str, timeframe: str):
        """æ£€æŸ¥Aç‚¹æœ‰æ•ˆæ€§ï¼Œå¦‚æœè¶…å‡º34æ ¹Kçº¿åˆ™é‡æ–°è·å–"""
        try:
            # è·å–æœ€æ–°Kçº¿æ•°æ®
            klines = self._get_klines_data(symbol, timeframe, 55)
            if not klines or len(klines) < 34:
                logger.warning(f"{symbol} Kçº¿æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ£€æŸ¥Aç‚¹æœ‰æ•ˆæ€§")
                return
            
            cache_key = f"{symbol}_{timeframe}"
            
            # æ£€æŸ¥åŒé¡¶Aç‚¹
            if cache_key in self.pattern_cache:
                cache = self.pattern_cache[cache_key]
                
                # æ£€æŸ¥åŒé¡¶Aç‚¹æ˜¯å¦è¿‡æœŸ
                if cache.a_point and cache.a_point.point_type == 'high':
                    if self._is_point_expired(cache.a_point, klines):
                        logger.info(f"{symbol} åŒé¡¶Aç‚¹å·²è¿‡æœŸï¼Œé‡æ–°è·å–")
                        # é‡æ–°è·å–Aç‚¹
                        extreme_points = self._detect_extreme_points(klines)
                        high_points = [p for p in extreme_points if p.point_type == 'high']
                        if high_points:
                            # é€‰æ‹©æœ€è¿‘çš„é«˜ç‚¹ä½œä¸ºæ–°çš„Aç‚¹
                            new_a_point = high_points[-1]
                            cache.a_point = new_a_point
                            cache.last_update = datetime.now()
                            logger.info(f"{symbol} åŒé¡¶Aç‚¹å·²æ›´æ–°: {new_a_point.price} @ {new_a_point.timestamp}")
                
                # æ£€æŸ¥åŒåº•Aç‚¹æ˜¯å¦è¿‡æœŸ
                if cache.a_point and cache.a_point.point_type == 'low':
                    if self._is_point_expired(cache.a_point, klines):
                        logger.info(f"{symbol} åŒåº•Aç‚¹å·²è¿‡æœŸï¼Œé‡æ–°è·å–")
                        # é‡æ–°è·å–Aç‚¹
                        extreme_points = self._detect_extreme_points(klines)
                        low_points = [p for p in extreme_points if p.point_type == 'low']
                        if low_points:
                            # é€‰æ‹©æœ€è¿‘çš„ä½ç‚¹ä½œä¸ºæ–°çš„Aç‚¹
                            new_a_point = low_points[-1]
                            cache.a_point = new_a_point
                            cache.last_update = datetime.now()
                            logger.info(f"{symbol} åŒåº•Aç‚¹å·²æ›´æ–°: {new_a_point.price} @ {new_a_point.timestamp}")
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥Aç‚¹æœ‰æ•ˆæ€§å¤±è´¥ {symbol}: {str(e)}")

    def _is_point_expired(self, point: ExtremePoint, klines: List[List]) -> bool:
        """æ£€æŸ¥ç¼“å­˜ç‚¹æ˜¯å¦è¿‡æœŸï¼ˆè¶…å‡ºæœ‰æ•ˆèŒƒå›´ï¼‰"""
        if not point:
            return True
        
        # æ£€æŸ¥ç‚¹æ˜¯å¦è¿˜åœ¨Kçº¿æ•°æ®çš„æœ‰æ•ˆèŒƒå›´å†…
        for i, kline in enumerate(klines):
            # ä¿®å¤ç±»å‹è½¬æ¢ï¼šç¡®ä¿æ—¶é—´æˆ³æ¯”è¾ƒæ—¶ç±»å‹ä¸€è‡´
            if int(kline[0]) == point.timestamp:
                position_from_right = len(klines) - 1 - i
                # Aç‚¹åº”è¯¥åœ¨ç¬¬13-34æ ¹èŒƒå›´å†…
                if 13 <= position_from_right <= 34:
                    return False
                # Dç‚¹åº”è¯¥åœ¨ç¬¬35-55æ ¹èŒƒå›´å†…  
                elif 35 <= position_from_right <= 55:
                    return False
        
        return True
    
    def _calculate_atr(self, klines: List[List], period: int = 14) -> float:
        """è®¡ç®—14å‘¨æœŸATRï¼ˆä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰"""
        if len(klines) < period + 1:
            return 0.0
        
        true_ranges = []
        
        for i in range(1, len(klines)):
            current = klines[i]
            previous = klines[i - 1]
            
            high = float(current[2])      # ç¡®ä¿ä¸ºæµ®ç‚¹æ•°
            low = float(current[3])       # ç¡®ä¿ä¸ºæµ®ç‚¹æ•°
            prev_close = float(previous[4])  # ç¡®ä¿ä¸ºæµ®ç‚¹æ•°
            
            tr1 = high - low
            tr2 = abs(high - prev_close)
            tr3 = abs(low - prev_close)
            
            true_range = max(tr1, tr2, tr3)
            true_ranges.append(true_range)
        
        # è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡ATR
        if len(true_ranges) >= period:
            multiplier = 2.0 / (period + 1)
            atr = true_ranges[0]  # åˆå§‹å€¼
            
            for tr in true_ranges[1:period]:
                atr = (tr * multiplier) + (atr * (1 - multiplier))
            
            return atr
        
        return 0.0
    
    def _get_cached_atr(self, symbol: str, timeframe: str, klines: List[List]) -> float:
        """è·å–ç¼“å­˜çš„ATRå€¼"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        cached_atr = self.data_cache.get_atr(symbol, timeframe)
        if cached_atr:
            return cached_atr
        
        # è®¡ç®—æ–°çš„ATR
        atr_klines = klines[:-1]  # ä½¿ç”¨å‰ä¸€æ ¹æ”¶ç›˜Kçº¿
        atr = self._calculate_atr(atr_klines)
        
        # ç¼“å­˜ç»“æœ
        if atr > 0:
            self.data_cache.set_atr(symbol, timeframe, atr)
        
        return atr
    
    def _find_point_between(self, klines: List[List], point_a: ExtremePoint, point_b: ExtremePoint, find_type: str) -> Optional[ExtremePoint]:
        """åœ¨ä¸¤ç‚¹ä¹‹é—´æŸ¥æ‰¾æå€¼ç‚¹"""
        start_time = min(point_a.timestamp, point_b.timestamp)
        end_time = max(point_a.timestamp, point_b.timestamp)
        
        extreme_price = float('inf') if find_type == 'low' else float('-inf')
        extreme_timestamp = None
        
        for kline in klines:
            kline_time = int(kline[0])
            if start_time < kline_time < end_time:
                price = float(kline[3]) if find_type == 'low' else float(kline[2])  # low or highï¼Œç¡®ä¿ä¸ºæµ®ç‚¹æ•°
                
                if find_type == 'low' and price < extreme_price:
                    extreme_price = price
                    extreme_timestamp = kline_time
                elif find_type == 'high' and price > extreme_price:
                    extreme_price = price
                    extreme_timestamp = kline_time
        
        if extreme_timestamp:
            return ExtremePoint(extreme_timestamp, extreme_price, find_type)
        
        return None
    
    def _detect_double_top(self, symbol: str, timeframe: str) -> Optional[Dict]:
        """æ£€æµ‹åŒé¡¶å½¢æ€"""
        cache_key = f"{symbol}_{timeframe}"
        
        if cache_key not in self.pattern_cache:
            return None
        
        cache = self.pattern_cache[cache_key]['double_top']
        if not cache.a_point:
            logger.info(f"æ­£åœ¨è·å–{symbol}çš„A_topç‚¹")
            return None
        
        # A_topç‚¹ï¼šç¼“å­˜çš„ç¬¬ä¸€ä¸ªé¡¶éƒ¨
        a_top = cache.a_point
        a_time = datetime.fromtimestamp(a_top.timestamp/1000).strftime('%Yå¹´%mæœˆ%dæ—¥%H:%M')
        logger.info(f"å·²è·å–A_topç‚¹ï¼šæœ€é«˜ä»·ä¸º{a_top.price:.2f}ï¼Œæ—¶é—´æˆ³ä¸º{a_time}")
        logger.info(f"A_topç‚¹å·²å­˜å…¥ç¼“å­˜ä¸­ï¼Œç­‰å¾…å’ŒB_topç‚¹è¿›è¡Œæ¯”è¾ƒ")
        
        # è·å–æœ€æ–°Kçº¿æ•°æ®
        klines = self._get_klines_data(symbol, timeframe, 55)
        if not klines or len(klines) < 35:
            return None
        
        # B_topç‚¹ï¼šæœ€æ–°æ”¶ç›˜Kçº¿çš„æœ€é«˜ä»·
        latest_kline = klines[-1]
        b_top = ExtremePoint(
            timestamp=int(latest_kline[0]),
            price=float(latest_kline[2]),  # æœ€é«˜ä»·
            point_type='high'
        )
        
        b_time = datetime.fromtimestamp(b_top.timestamp/1000).strftime('%Yå¹´%mæœˆ%dæ—¥%Hç‚¹')
        logger.info(f"ç°åœ¨è·å–{symbol}æœ€æ–°æ”¶ç›˜Kçº¿B_topç‚¹")
        logger.info(f"B_topç‚¹æ—¶é—´æˆ³ä¸º{b_time}ï¼Œæœ€é«˜ä»·ä¸º{b_top.price:.2f}")
        
        # è·å–ATR
        logger.info(f"æ­£åœ¨è®¡ç®—B_topç‚¹å¯¹åº”çš„ATR")
        atr = self._get_cached_atr(symbol, timeframe, klines)
        if atr <= 0:
            return None
        
        logger.info(f"ATRä¸º{atr:.2f}")
        
        # éªŒè¯A_topä¸B_topå·®å€¼ â‰¤ 0.8ATR
        ab_diff = abs(a_top.price - b_top.price)
        atr_threshold = 0.8 * atr
        logger.info(f"A_topä¸B_topçš„ç»å¯¹è·ç¦»ä¸º{ab_diff:.2f}ï¼Œ{'å°äºç­‰äº' if ab_diff <= atr_threshold else 'å¤§äº'}0.8*ATR({atr_threshold:.2f})ï¼ŒB_topç‚¹{'æœ‰æ•ˆ' if ab_diff <= atr_threshold else 'æ— æ•ˆ'}")
        
        if ab_diff > atr_threshold:
            return None
        
        # éªŒè¯åŒé¡¶è¿‡æ»¤æ¡ä»¶ï¼šA_topå’ŒB_topä¹‹é—´ä¸å¾—å­˜åœ¨é«˜äºè¿™ä¸¤ä¸ªé¡¶ç‚¹çš„ä»·æ ¼
        max_ab_price = max(a_top.price, b_top.price)
        start_time = min(a_top.timestamp, b_top.timestamp)
        end_time = max(a_top.timestamp, b_top.timestamp)
        
        for kline in klines:
            kline_time = int(kline[0])
            if start_time < kline_time < end_time:
                high_price = float(kline[2])  # æœ€é«˜ä»·
                if high_price > max_ab_price:
                    logger.info(f"åŒé¡¶è¿‡æ»¤ï¼šåœ¨A_topå’ŒB_topä¹‹é—´å‘ç°æ›´é«˜ä»·æ ¼{high_price:.2f}ï¼Œé«˜äºmax(A_top,B_top)={max_ab_price:.2f}ï¼Œä¸ç¬¦åˆåŒé¡¶å®šä¹‰")
                    return None
        
        logger.info(f"åŒé¡¶è¿‡æ»¤é€šè¿‡ï¼šA_topå’ŒB_topä¹‹é—´æ— é«˜äº{max_ab_price:.2f}çš„ä»·æ ¼")
        
        # æŸ¥æ‰¾C_bottomç‚¹ï¼ˆA_topä¸B_topé—´æœ€ä½ç‚¹ï¼‰
        logger.info(f"ç°åœ¨è·å–A_topä¸B_topä¹‹é—´çš„C_bottomç‚¹")
        c_bottom = self._find_point_between(klines, a_top, b_top, 'low')
        if not c_bottom:
            logger.info(f"æœªæ‰¾åˆ°C_bottomç‚¹ï¼ŒåŒé¡¶æ£€æµ‹å¤±è´¥")
            return None
        
        c_time = datetime.fromtimestamp(c_bottom.timestamp/1000).strftime('%Yå¹´%mæœˆ%dæ—¥%Hç‚¹')
        logger.info(f"C_bottomç‚¹ä½{c_bottom.price:.2f}ï¼Œæ—¶é—´æˆ³ä¸º{c_time}")
        
        # éªŒè¯max(A_top,B_top) - C_bottom â‰¥ 2.3ATR
        max_ab = max(a_top.price, b_top.price)
        c_diff = abs(max_ab - c_bottom.price)
        atr_c_threshold = 2.3 * atr
        logger.info(f"ç°åœ¨è®¡ç®—C_bottomç‚¹ä¸max[A_top,B_top]çš„ç»å¯¹è·ç¦»ï¼Œç»å¯¹è·ç¦»ä¸º{c_diff:.2f}")
        logger.info(f"{'å¤§äºç­‰äº' if c_diff >= atr_c_threshold else 'å°äº'}2.3*ATR({atr_c_threshold:.2f})ï¼Œ{'ç¬¦åˆ' if c_diff >= atr_c_threshold else 'ä¸ç¬¦åˆ'}åŒé¡¶å½¢æ€")
        
        if c_diff < atr_c_threshold:
            return None
        
        logger.info(f"âœ“ æ£€æµ‹åˆ°åŒé¡¶å½¢æ€: {symbol} {timeframe} [A_top:{a_top.price:.2f}, B_top:{b_top.price:.2f}, C_bottom:{c_bottom.price:.2f}]")
        
        return {
            'pattern_type': 'double_top',
            'symbol': symbol,
            'timeframe': timeframe,
            'point_a': {'timestamp': datetime.fromtimestamp(a_top.timestamp/1000).isoformat(), 'price': a_top.price, 'type': a_top.point_type},
            'point_b': {'timestamp': datetime.fromtimestamp(b_top.timestamp/1000).isoformat(), 'price': b_top.price, 'type': b_top.point_type},
            'point_c': {'timestamp': datetime.fromtimestamp(c_bottom.timestamp/1000).isoformat(), 'price': c_bottom.price, 'type': c_bottom.point_type},
            'atr': atr,
            'quality_score': min(100, (c_diff / (2.3 * atr)) * 100)
        }
    
    def _detect_double_bottom(self, symbol: str, timeframe: str) -> Optional[Dict]:
        """æ£€æµ‹åŒåº•å½¢æ€"""
        cache_key = f"{symbol}_{timeframe}"
        
        if cache_key not in self.pattern_cache:
            return None
        
        cache = self.pattern_cache[cache_key]['double_bottom']
        if not cache.a_point:
            return None
        
        # è·å–æœ€æ–°Kçº¿æ•°æ®
        klines = self._get_klines_data(symbol, timeframe, 55)
        if not klines or len(klines) < 35:
            return None
        
        # A_bottomç‚¹ï¼šç¼“å­˜çš„ç¬¬ä¸€ä¸ªåº•éƒ¨
        a_bottom = cache.a_point
        a_time = datetime.fromtimestamp(a_bottom.timestamp/1000)
        logger.info(f"æ­£åœ¨è·å–{symbol}çš„A_bottomç‚¹")
        logger.info(f"å·²è·å–A_bottomç‚¹ï¼šæœ€ä½ä»·ä¸º{a_bottom.price}ï¼Œæ—¶é—´æˆ³ä¸º{a_time.strftime('%Yå¹´%mæœˆ%dæ—¥%H:%M')}")
        logger.info(f"A_bottomç‚¹å·²å­˜å…¥ç¼“å­˜ä¸­ï¼Œç­‰å¾…å’ŒB_bottomç‚¹è¿›è¡Œæ¯”è¾ƒ")
        
        # B_bottomç‚¹ï¼šæœ€æ–°æ”¶ç›˜Kçº¿çš„æœ€ä½ä»·
        latest_kline = klines[-1]
        b_bottom = ExtremePoint(
            timestamp=int(latest_kline[0]),
            price=float(latest_kline[3]),  # æœ€ä½ä»·
            point_type='low'
        )
        
        b_time = datetime.fromtimestamp(b_bottom.timestamp/1000)
        logger.info(f"ç°åœ¨è·å–{symbol}æœ€æ–°æ”¶ç›˜Kçº¿B_bottomç‚¹")
        logger.info(f"B_bottomç‚¹æ—¶é—´æˆ³ä¸º{b_time.strftime('%Yå¹´%mæœˆ%dæ—¥%Hç‚¹')}ï¼Œæœ€ä½ä»·ä¸º{b_bottom.price}")
        
        # è·å–ATR
        atr = self._get_cached_atr(symbol, timeframe, klines)
        if atr <= 0:
            return None
        
        logger.info(f"æ­£åœ¨è®¡ç®—B_bottomç‚¹å¯¹åº”çš„ATRï¼ŒATRä¸º{atr}")
        
        # éªŒè¯A_bottomä¸B_bottomå·®å€¼ â‰¤ 0.8ATR
        ab_diff = abs(a_bottom.price - b_bottom.price)
        atr_threshold = 0.8 * atr
        logger.info(f"A_bottomä¸B_bottomçš„ç»å¯¹è·ç¦»ä¸º{ab_diff}ï¼Œ{'å°äºç­‰äº' if ab_diff <= atr_threshold else 'å¤§äº'}0.8*ATR({atr_threshold:.2f})ï¼ŒB_bottomç‚¹{'æœ‰æ•ˆ' if ab_diff <= atr_threshold else 'æ— æ•ˆ'}")
        
        if ab_diff > atr_threshold:
            return None
        
        # éªŒè¯åŒåº•è¿‡æ»¤æ¡ä»¶ï¼šA_bottomå’ŒB_bottomä¹‹é—´ä¸å¾—å­˜åœ¨ä½äºè¿™ä¸¤ä¸ªåº•ç‚¹çš„ä»·æ ¼
        min_ab_price = min(a_bottom.price, b_bottom.price)
        start_time = min(a_bottom.timestamp, b_bottom.timestamp)
        end_time = max(a_bottom.timestamp, b_bottom.timestamp)
        
        for kline in klines:
            kline_time = int(kline[0])
            if start_time < kline_time < end_time:
                low_price = float(kline[3])  # æœ€ä½ä»·
                if low_price < min_ab_price:
                    logger.info(f"åŒåº•è¿‡æ»¤ï¼šåœ¨A_bottomå’ŒB_bottomä¹‹é—´å‘ç°æ›´ä½ä»·æ ¼{low_price:.2f}ï¼Œä½äºmin(A_bottom,B_bottom)={min_ab_price:.2f}ï¼Œä¸ç¬¦åˆåŒåº•å®šä¹‰")
                    return None
        
        logger.info(f"åŒåº•è¿‡æ»¤é€šè¿‡ï¼šA_bottomå’ŒB_bottomä¹‹é—´æ— ä½äº{min_ab_price:.2f}çš„ä»·æ ¼")
        
        # æŸ¥æ‰¾C_topç‚¹ï¼ˆA_bottomä¸B_bottomé—´æœ€é«˜ç‚¹ï¼‰
        logger.info(f"ç°åœ¨è·å–A_bottomä¸B_bottomä¹‹é—´çš„C_topç‚¹")
        c_top = self._find_point_between(klines, a_bottom, b_bottom, 'high')
        if not c_top:
            logger.info(f"æœªæ‰¾åˆ°C_topç‚¹ï¼ŒåŒåº•æ£€æµ‹å¤±è´¥")
            return None
        
        c_time = datetime.fromtimestamp(c_top.timestamp/1000)
        logger.info(f"C_topç‚¹ä½{c_top.price}ï¼Œæ—¶é—´æˆ³ä¸º{c_time.strftime('%Yå¹´%mæœˆ%dæ—¥%Hç‚¹')}")
        
        # éªŒè¯C_top - min(A_bottom,B_bottom) â‰¥ 2.3ATR
        min_ab = min(a_bottom.price, b_bottom.price)
        c_diff = abs(c_top.price - min_ab)
        atr_c_threshold = 2.3 * atr
        logger.info(f"ç°åœ¨è®¡ç®—C_topç‚¹ä¸min[A_bottom,B_bottom]çš„ç»å¯¹è·ç¦»ï¼Œç»å¯¹è·ç¦»ä¸º{c_diff}")
        logger.info(f"{'å¤§äºç­‰äº' if c_diff >= atr_c_threshold else 'å°äº'}2.3*ATR({atr_c_threshold:.2f})ï¼Œ{'ç¬¦åˆ' if c_diff >= atr_c_threshold else 'ä¸ç¬¦åˆ'}åŒåº•å½¢æ€")
        
        if c_diff < atr_c_threshold:
            return None
        
        logger.info(f"âœ“ æ£€æµ‹åˆ°åŒåº•å½¢æ€: {symbol} {timeframe} [A_bottom:{a_bottom.price}, B_bottom:{b_bottom.price}, C_top:{c_top.price}]")
        
        return {
            'pattern_type': 'double_bottom',
            'symbol': symbol,
            'timeframe': timeframe,
            'point_a': {'timestamp': datetime.fromtimestamp(a_bottom.timestamp/1000).isoformat(), 'price': a_bottom.price, 'type': a_bottom.point_type},
            'point_b': {'timestamp': datetime.fromtimestamp(b_bottom.timestamp/1000).isoformat(), 'price': b_bottom.price, 'type': b_bottom.point_type},
            'point_c': {'timestamp': datetime.fromtimestamp(c_top.timestamp/1000).isoformat(), 'price': c_top.price, 'type': c_top.point_type},
            'atr': atr,
            'quality_score': min(100, (c_diff / (2.3 * atr)) * 100)
        }
    

    

    
    def _calculate_additional_indicators(self, symbol: str, timeframe: str, pattern_result: Dict) -> Dict:
        """è®¡ç®—é¢å¤–çš„æŠ€æœ¯æŒ‡æ ‡ï¼ˆä»…åœ¨å½¢æ€ç¡®è®¤åï¼‰"""
        # è·å–144æ ¹Kçº¿ç”¨äºè®¡ç®—EMA
        klines = self._get_klines_data(symbol, timeframe, 144)
        if not klines or len(klines) < 144:
            return {}
        
        # æå–æ”¶ç›˜ä»·
        closes = [float(kline[4]) for kline in klines]  # ä¿®å¤ï¼šç¡®ä¿æ”¶ç›˜ä»·ä¸ºæµ®ç‚¹æ•°
        
        # è®¡ç®—EMA
        ema21 = self._calculate_ema(closes, 21)
        ema55 = self._calculate_ema(closes, 55)
        ema144 = self._calculate_ema(closes, 144)
        
        # åˆ¤æ–­EMAè¶‹åŠ¿
        ema_trend = self._determine_ema_trend(ema21, ema55, ema144)
        
        # åˆ†æKçº¿å½¢æ€
        kline_pattern = self._analyze_kline_pattern(klines)
        
        return {
            'ema21': ema21,
            'ema55': ema55,
            'ema144': ema144,
            'ema_trend': ema_trend,
            'kline_pattern': kline_pattern
        }
    
    def _calculate_ema(self, prices: List[float], period: int) -> float:
        """è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿"""
        if len(prices) < period:
            return 0.0
        
        multiplier = 2 / (period + 1)
        ema = prices[0]
        
        for price in prices[1:]:
            ema = (price * multiplier) + (ema * (1 - multiplier))
        
        return ema
    

    
    def _determine_ema_trend(self, ema21: float, ema55: float, ema144: float) -> str:
        """åˆ¤æ–­EMAè¶‹åŠ¿"""
        if not (ema21 and ema55 and ema144):
            return "unknown"
            
        if ema21 > ema55 > ema144:
            return "bullish"  # å¤šå¤´æ’åˆ—
        elif ema21 < ema55 < ema144:
            return "bearish"  # ç©ºå¤´æ’åˆ—
        else:
            return "neutral"  # ä¸­æ€§/æ··ä¹±æ’åˆ—
    
    def _calculate_ema_convergence(self, ema21: float, ema55: float, ema144: float, atr: float) -> float:
        """è®¡ç®—EMAèšåˆåº¦"""
        try:
            if atr <= 0:
                return float('inf')
            
            # è®¡ç®—EMAä¹‹é—´çš„æœ€å¤§è·¨åº¦
            ema_values = [ema21, ema55, ema144]
            span = max(ema_values) - min(ema_values)
            
            # è®¡ç®—èšåˆåº¦æ¯”ç‡ï¼ˆè·¨åº¦/ATRï¼‰
            convergence_ratio = span / atr
            
            return convergence_ratio
            
        except Exception as e:
            logger.error(f"è®¡ç®—EMAèšåˆåº¦æ—¶å‡ºé”™: {e}")
            return float('inf')
    
    def _calculate_ema_series(self, prices: List[float], period: int) -> List[Optional[float]]:
        """è®¡ç®—EMAåºåˆ—"""
        try:
            ema_values = []
            multiplier = 2.0 / (period + 1)
            
            for i in range(len(prices)):
                if i < period - 1:
                    ema_values.append(None)
                elif i == period - 1:
                    # ç¬¬ä¸€ä¸ªEMAå€¼ä½¿ç”¨SMA
                    sma = sum(prices[:period]) / period
                    ema_values.append(sma)
                else:
                    # åç»­EMAå€¼
                    prev_ema = ema_values[i-1]
                    current_ema = (prices[i] * multiplier) + (prev_ema * (1 - multiplier))
                    ema_values.append(current_ema)
            
            return ema_values
            
        except Exception as e:
            logger.error(f"è®¡ç®—EMAåºåˆ—æ—¶å‡ºé”™: {e}")
            return [None] * len(prices)
    
    def _identify_ema_alignment(self, ema21_values: List[Optional[float]], 
                              ema55_values: List[Optional[float]], 
                              ema144_values: List[Optional[float]], 
                              current_idx: int) -> Optional[Dict]:
        """è¯†åˆ«EMAæ’åˆ—çŠ¶æ€"""
        try:
            if current_idx < 1:
                return None
            
            # å½“å‰å’Œå‰ä¸€æ ¹Kçº¿çš„EMAå€¼
            current_ema21 = ema21_values[current_idx]
            current_ema55 = ema55_values[current_idx]
            current_ema144 = ema144_values[current_idx]
            
            prev_ema21 = ema21_values[current_idx - 1]
            prev_ema55 = ema55_values[current_idx - 1]
            prev_ema144 = ema144_values[current_idx - 1]
            
            if None in [current_ema21, current_ema55, current_ema144, prev_ema21, prev_ema55, prev_ema144]:
                return None
            
            # åˆ¤æ–­å½“å‰æ’åˆ—
            current_alignment = None
            if current_ema21 > current_ema55 > current_ema144:
                current_alignment = 'bullish'
            elif current_ema21 < current_ema55 < current_ema144:
                current_alignment = 'bearish'
            else:
                current_alignment = 'mixed'
            
            # åˆ¤æ–­å‰ä¸€æ ¹æ’åˆ—
            prev_alignment = None
            if prev_ema21 > prev_ema55 > prev_ema144:
                prev_alignment = 'bullish'
            elif prev_ema21 < prev_ema55 < prev_ema144:
                prev_alignment = 'bearish'
            else:
                prev_alignment = 'mixed'
            
            # è®¡ç®—æ’åˆ—å¼ºåº¦ï¼ˆEMAä¹‹é—´çš„ç›¸å¯¹è·ç¦»ï¼‰
            strength = 0.0
            if current_alignment in ['bullish', 'bearish']:
                diff1 = abs(current_ema21 - current_ema55)
                diff2 = abs(current_ema55 - current_ema144)
                avg_price = (current_ema21 + current_ema55 + current_ema144) / 3
                if avg_price > 0:
                    strength = (diff1 + diff2) / (2 * avg_price) * 100
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ–°çš„æ’åˆ—
            is_new_alignment = (current_alignment in ['bullish', 'bearish'] and 
                              current_alignment != prev_alignment)
            
            return {
                'alignment': current_alignment,
                'prev_alignment': prev_alignment,
                'is_new_alignment': is_new_alignment,
                'strength': strength
            }
            
        except Exception as e:
            logger.error(f"è¯†åˆ«EMAæ’åˆ—æ—¶å‡ºé”™: {e}")
            return None
    
    def _detect_ema_trend_signal(self, symbol: str, timeframe: str, convergence_threshold: float = 0.5) -> Optional[Dict]:
        """æ£€æµ‹EMAè¶‹åŠ¿ä¿¡å·ï¼Œé›†æˆæ›´å®Œæ•´çš„EMAæ’åˆ—æ£€æµ‹é€»è¾‘"""
        try:
            logger.info(f"å¼€å§‹åˆ†æ{symbol}çš„EMAè¶‹åŠ¿ä¿¡å·")
            
            # è·å–è¶³å¤Ÿçš„Kçº¿æ•°æ®ç”¨äºè®¡ç®—
            klines = self._get_klines_data(symbol, timeframe, 200)
            if not klines or len(klines) < 200:
                logger.info(f"Kçº¿æ•°æ®ä¸è¶³ï¼Œéœ€è¦200æ ¹Kçº¿ï¼Œå®é™…è·å–{len(klines) if klines else 0}æ ¹")
                return None
            
            logger.info(f"å·²è·å–{len(klines)}æ ¹Kçº¿æ•°æ®ï¼Œå¼€å§‹è®¡ç®—EMAæŒ‡æ ‡")
            
            # æå–æ”¶ç›˜ä»·
            closes = [float(kline[4]) for kline in klines]
            
            # è®¡ç®—EMAæŒ‡æ ‡
            ema21_values = self._calculate_ema_series(closes, 21)
            ema55_values = self._calculate_ema_series(closes, 55)
            ema144_values = self._calculate_ema_series(closes, 144)
            
            logger.info(f"å·²å®ŒæˆEMA21ã€EMA55ã€EMA144çš„è®¡ç®—")
            
            # è®¡ç®—ATR
            atr_values = []
            for i in range(len(klines)):
                if i >= 13:
                    segment_klines = klines[max(0, i-13):i+1]
                    atr = self._calculate_atr(segment_klines, 14)
                    atr_values.append(atr)
                else:
                    atr_values.append(None)
            
            logger.info(f"å·²å®ŒæˆATRè®¡ç®—")
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            current_idx = len(klines) - 1
            if (current_idx < 144 or 
                ema21_values[current_idx] is None or ema55_values[current_idx] is None or 
                ema144_values[current_idx] is None or atr_values[current_idx] is None):
                logger.info(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•è¿›è¡ŒEMAæ’åˆ—åˆ†æ")
                return None
            
            current_time = datetime.fromtimestamp(klines[current_idx][0]/1000)
            logger.info(f"å½“å‰Kçº¿æ—¶é—´æˆ³ä¸º{current_time.strftime('%Yå¹´%mæœˆ%dæ—¥%Hç‚¹')}ï¼Œä»·æ ¼ä¸º{closes[current_idx]}")
            logger.info(f"å½“å‰EMA21={ema21_values[current_idx]:.2f}, EMA55={ema55_values[current_idx]:.2f}, EMA144={ema144_values[current_idx]:.2f}")
            
            # è¯†åˆ«EMAæ’åˆ—çŠ¶æ€
            alignment_result = self._identify_ema_alignment(
                ema21_values, ema55_values, ema144_values, current_idx
            )
            
            if not alignment_result:
                logger.info(f"æœªè¯†åˆ«åˆ°æœ‰æ•ˆçš„EMAæ’åˆ—çŠ¶æ€")
                return None
            
            logger.info(f"å½“å‰EMAæ’åˆ—çŠ¶æ€ï¼š{alignment_result['alignment']}ï¼Œå‰ä¸€æ ¹Kçº¿æ’åˆ—çŠ¶æ€ï¼š{alignment_result['prev_alignment']}")
            logger.info(f"æ˜¯å¦ä¸ºæ–°æ’åˆ—ï¼š{alignment_result['is_new_alignment']}")
            
            # ä»…åœ¨è¯†åˆ«åˆ°æ–°çš„ä¸Šå‡è¶‹åŠ¿ï¼ˆå¤šå¤´æ’åˆ—ï¼‰æˆ–æ–°çš„ä¸‹é™è¶‹åŠ¿ï¼ˆç©ºå¤´æ’åˆ—ï¼‰æ—¶æ‰è®¡ç®—èšåˆåº¦
            if alignment_result['alignment'] in ['bullish', 'bearish'] and alignment_result['is_new_alignment']:
                logger.info(f"æ£€æµ‹åˆ°æ–°çš„{'å¤šå¤´' if alignment_result['alignment'] == 'bullish' else 'ç©ºå¤´'}æ’åˆ—ï¼Œå¼€å§‹è®¡ç®—èšåˆåº¦")
                
                # è®¡ç®—èšåˆåº¦
                convergence = self._calculate_ema_convergence(
                    ema21_values[current_idx],
                    ema55_values[current_idx], 
                    ema144_values[current_idx],
                    atr_values[current_idx]
                )
                
                logger.info(f"è®¡ç®—å¾—å‡ºèšåˆåº¦ä¸º{convergence:.3f}ï¼Œé˜ˆå€¼ä¸º{convergence_threshold}")
                
                # æ£€æŸ¥èšåˆåº¦æ¡ä»¶
                if convergence >= convergence_threshold:
                    logger.info(f"èšåˆåº¦{convergence:.3f}å¤§äºç­‰äºé˜ˆå€¼{convergence_threshold}ï¼Œä¸ç¬¦åˆè¶‹åŠ¿ä¿¡å·æ¡ä»¶")
                    return None
                
                logger.info(f"èšåˆåº¦{convergence:.3f}å°äºé˜ˆå€¼{convergence_threshold}ï¼Œç¬¦åˆè¶‹åŠ¿ä¿¡å·æ¡ä»¶")
                
                # å¤šå¤´ä¿¡å·ï¼šå¤šå¤´æ’åˆ—
                if alignment_result['alignment'] == 'bullish':
                    logger.info(f"âœ“ æ£€æµ‹åˆ°å¤šå¤´EMAè¶‹åŠ¿ä¿¡å·: {symbol} {timeframe}")
                    return {
                        'type': 'ema_trend',
                        'signal': 'bullish',
                        'symbol': symbol,
                        'timeframe': timeframe,
                        'timestamp': int(klines[current_idx][0]),
                        'price': closes[current_idx],
                        'ema21': ema21_values[current_idx],
                        'ema55': ema55_values[current_idx],
                        'ema144': ema144_values[current_idx],
                        'convergence': convergence,
                        'atr': atr_values[current_idx],
                        'alignment_strength': alignment_result['strength']
                    }
                
                # ç©ºå¤´ä¿¡å·ï¼šç©ºå¤´æ’åˆ—
                elif alignment_result['alignment'] == 'bearish':
                    logger.info(f"âœ“ æ£€æµ‹åˆ°ç©ºå¤´EMAè¶‹åŠ¿ä¿¡å·: {symbol} {timeframe}")
                    return {
                        'type': 'ema_trend',
                        'signal': 'bearish',
                        'symbol': symbol,
                        'timeframe': timeframe,
                        'timestamp': int(klines[current_idx][0]),
                        'price': closes[current_idx],
                        'ema21': ema21_values[current_idx],
                        'ema55': ema55_values[current_idx],
                        'ema144': ema144_values[current_idx],
                        'convergence': convergence,
                        'atr': atr_values[current_idx],
                        'alignment_strength': alignment_result['strength']
                    }
            else:
                logger.info(f"å½“å‰æ’åˆ—çŠ¶æ€ä¸º{alignment_result['alignment']}ï¼Œä¸æ˜¯æ–°çš„å¤šå¤´æˆ–ç©ºå¤´æ’åˆ—ï¼Œæ— éœ€å‘é€ä¿¡å·")
            
            return None
            
        except Exception as e:
            logger.error(f"æ£€æµ‹EMAè¶‹åŠ¿ä¿¡å·æ—¶å‡ºé”™: {e}")
            return None
    
    def _analyze_kline_pattern(self, klines: List[List]) -> Dict:
        """åˆ†æKçº¿å½¢æ€"""
        if len(klines) < 3:
            return {'pattern': 'none', 'strength': 0}
        
        # è·å–æœ€è¿‘3æ ¹Kçº¿
        current = klines[-1]  # [timestamp, open, high, low, close, volume]
        prev1 = klines[-2]
        prev2 = klines[-3]
        
        patterns = []
        
        # æ£€æµ‹é”¤å­çº¿
        hammer = self._detect_hammer(current)
        if hammer['detected']:
            patterns.append(hammer)
        
        # æ£€æµ‹åæ²¡å½¢æ€
        engulfing = self._detect_engulfing(prev1, current)
        if engulfing['detected']:
            patterns.append(engulfing)
        
        # æ£€æµ‹åå­—æ˜Ÿ
        doji = self._detect_doji(current)
        if doji['detected']:
            patterns.append(doji)
        
        # æ£€æµ‹ä¸‰æ ¹Kçº¿å½¢æ€
        three_candle = self._detect_three_candle_patterns(prev2, prev1, current)
        if three_candle['detected']:
            patterns.append(three_candle)
        
        if not patterns:
            return {'pattern': 'none', 'strength': 0}
        
        # è¿”å›æœ€å¼ºçš„å½¢æ€
        strongest = max(patterns, key=lambda x: x['strength'])
        return strongest
    
    def _detect_hammer(self, candle: List) -> Dict:
        """æ£€æµ‹é”¤å­çº¿å½¢æ€"""
        open_price, high, low, close = float(candle[1]), float(candle[2]), float(candle[3]), float(candle[4])
        
        body = abs(close - open_price)
        upper_shadow = high - max(close, open_price)
        lower_shadow = min(close, open_price) - low
        total_range = high - low
        
        if total_range == 0:
            return {'detected': False, 'pattern': 'none', 'strength': 0}
        
        # é”¤å­çº¿æ¡ä»¶ï¼šä¸‹å½±çº¿é•¿åº¦è‡³å°‘æ˜¯å®ä½“çš„2å€ï¼Œä¸Šå½±çº¿å¾ˆçŸ­
        if (lower_shadow >= body * 2 and 
            upper_shadow <= body * 0.1 and 
            body > 0):
            
            pattern_type = 'hammer_bullish' if close > open_price else 'hammer_bearish'
            strength = min(90, (lower_shadow / total_range) * 100)
            
            return {
                'detected': True,
                'pattern': pattern_type,
                'strength': strength,
                'description': 'é”¤å­çº¿å½¢æ€'
            }
        
        return {'detected': False, 'pattern': 'none', 'strength': 0}
    
    def _detect_engulfing(self, prev_candle: List, current_candle: List) -> Dict:
        """æ£€æµ‹åæ²¡å½¢æ€"""
        prev_open, prev_close = float(prev_candle[1]), float(prev_candle[4])
        curr_open, curr_close = float(current_candle[1]), float(current_candle[4])
        
        prev_body = abs(prev_close - prev_open)
        curr_body = abs(curr_close - curr_open)
        
        if prev_body == 0 or curr_body == 0:
            return {'detected': False, 'pattern': 'none', 'strength': 0}
        
        # çœ‹æ¶¨åæ²¡ï¼šå‰ä¸€æ ¹é˜´çº¿ï¼Œå½“å‰é˜³çº¿å®Œå…¨åæ²¡å‰ä¸€æ ¹
        if (prev_close < prev_open and  # å‰ä¸€æ ¹æ˜¯é˜´çº¿
            curr_close > curr_open and   # å½“å‰æ˜¯é˜³çº¿
            curr_open < prev_close and   # å½“å‰å¼€ç›˜ä»·ä½äºå‰ä¸€æ ¹æ”¶ç›˜ä»·
            curr_close > prev_open):     # å½“å‰æ”¶ç›˜ä»·é«˜äºå‰ä¸€æ ¹å¼€ç›˜ä»·
            
            strength = min(95, (curr_body / prev_body) * 50 + 45)
            return {
                'detected': True,
                'pattern': 'bullish_engulfing',
                'strength': strength,
                'description': 'çœ‹æ¶¨åæ²¡å½¢æ€'
            }
        
        # çœ‹è·Œåæ²¡ï¼šå‰ä¸€æ ¹é˜³çº¿ï¼Œå½“å‰é˜´çº¿å®Œå…¨åæ²¡å‰ä¸€æ ¹
        if (prev_close > prev_open and  # å‰ä¸€æ ¹æ˜¯é˜³çº¿
            curr_close < curr_open and   # å½“å‰æ˜¯é˜´çº¿
            curr_open > prev_close and   # å½“å‰å¼€ç›˜ä»·é«˜äºå‰ä¸€æ ¹æ”¶ç›˜ä»·
            curr_close < prev_open):     # å½“å‰æ”¶ç›˜ä»·ä½äºå‰ä¸€æ ¹å¼€ç›˜ä»·
            
            strength = min(95, (curr_body / prev_body) * 50 + 45)
            return {
                'detected': True,
                'pattern': 'bearish_engulfing',
                'strength': strength,
                'description': 'çœ‹è·Œåæ²¡å½¢æ€'
            }
        
        return {'detected': False, 'pattern': 'none', 'strength': 0}
    
    def _detect_doji(self, candle: List) -> Dict:
        """æ£€æµ‹åå­—æ˜Ÿå½¢æ€"""
        open_price, high, low, close = float(candle[1]), float(candle[2]), float(candle[3]), float(candle[4])
        
        body = abs(close - open_price)
        total_range = high - low
        
        if total_range == 0:
            return {'detected': False, 'pattern': 'none', 'strength': 0}
        
        # åå­—æ˜Ÿæ¡ä»¶ï¼šå®ä½“å¾ˆå°ï¼ˆå°äºæ€»èŒƒå›´çš„5%ï¼‰
        if body <= total_range * 0.05:
            strength = max(60, 100 - (body / total_range) * 100)
            return {
                'detected': True,
                'pattern': 'doji',
                'strength': strength,
                'description': 'åå­—æ˜Ÿå½¢æ€'
            }
        
        return {'detected': False, 'pattern': 'none', 'strength': 0}
    
    def _detect_three_candle_patterns(self, candle1: List, candle2: List, candle3: List) -> Dict:
        """æ£€æµ‹ä¸‰æ ¹Kçº¿å½¢æ€"""
        # è·å–æ”¶ç›˜ä»·
        close1, close2, close3 = candle1[4], candle2[4], candle3[4]
        open1, open2, open3 = candle1[1], candle2[1], candle3[1]
        
        # æ£€æµ‹ä¸‰åªä¹Œé¸¦ï¼ˆä¸‰æ ¹è¿ç»­é˜´çº¿ï¼Œæ¯æ ¹éƒ½æ¯”å‰ä¸€æ ¹ä½ï¼‰
        if (close1 < open1 and close2 < open2 and close3 < open3 and  # ä¸‰æ ¹éƒ½æ˜¯é˜´çº¿
            close2 < close1 and close3 < close2):  # é€æ­¥èµ°ä½
            return {
                'detected': True,
                'pattern': 'three_black_crows',
                'strength': 85,
                'description': 'ä¸‰åªä¹Œé¸¦å½¢æ€'
            }
        
        # æ£€æµ‹ä¸‰ä¸ªç™½å…µï¼ˆä¸‰æ ¹è¿ç»­é˜³çº¿ï¼Œæ¯æ ¹éƒ½æ¯”å‰ä¸€æ ¹é«˜ï¼‰
        if (close1 > open1 and close2 > open2 and close3 > open3 and  # ä¸‰æ ¹éƒ½æ˜¯é˜³çº¿
            close2 > close1 and close3 > close2):  # é€æ­¥èµ°é«˜
            return {
                'detected': True,
                'pattern': 'three_white_soldiers',
                'strength': 85,
                'description': 'ä¸‰ä¸ªç™½å…µå½¢æ€'
            }
        
        return {'detected': False, 'pattern': 'none', 'strength': 0}
    
    def _find_kline_index_by_timestamp(self, klines: List[List], timestamp: int) -> int:
        """æ ¹æ®æ—¶é—´æˆ³æ‰¾åˆ°Kçº¿åœ¨æ•°ç»„ä¸­çš„ç´¢å¼•"""
        for i, kline in enumerate(klines):
            # ä¿®å¤ç±»å‹è½¬æ¢ï¼šç¡®ä¿æ—¶é—´æˆ³æ¯”è¾ƒæ—¶ç±»å‹ä¸€è‡´
            if int(kline[0]) == timestamp:
                return i
        return -1
    
    def _analyze_pattern(self, symbol: str, timeframe: str) -> Optional[Dict]:
        """åˆ†æå•ä¸ªäº¤æ˜“å¯¹çš„å½¢æ€"""
        try:
            logger.debug(f"å¼€å§‹åˆ†æå½¢æ€: {symbol} {timeframe}")
            
            # åˆå§‹åŒ–æˆ–æ›´æ–°å½¢æ€ç¼“å­˜
            cache_key = f"{symbol}_{timeframe}"
            if cache_key not in self.pattern_cache:
                logger.debug(f"åˆå§‹åŒ–å½¢æ€ç¼“å­˜: {symbol} {timeframe}")
                self._initialize_pattern_cache(symbol, timeframe)
            else:
                logger.debug(f"æ›´æ–°å½¢æ€ç¼“å­˜: {symbol} {timeframe}")
                self._update_pattern_cache(symbol, timeframe)
            
            detected_patterns = []
            
            # æ£€æµ‹åŒé¡¶/åŒåº•å½¢æ€
            pattern_types = ['åŒé¡¶', 'åŒåº•']
            patterns = [
                self._detect_double_top(symbol, timeframe),
                self._detect_double_bottom(symbol, timeframe)
            ]
            
            # æ”¶é›†æ‰€æœ‰æ£€æµ‹åˆ°çš„åŒé¡¶/åŒåº•å½¢æ€
            for i, pattern in enumerate(patterns):
                if pattern:
                    pattern_name = pattern_types[i]
                    quality_score = pattern.get('quality_score', 0)
                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å½¢æ€: {symbol} {timeframe} - {pattern_name} (è´¨é‡åˆ†æ•°: {quality_score:.2f})")
                    
                    # è®¡ç®—é¢å¤–æŒ‡æ ‡
                    logger.debug(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: {symbol} {timeframe}")
                    additional_indicators = self._calculate_additional_indicators(symbol, timeframe, pattern)
                    pattern.update(additional_indicators)
                    
                    # è®°å½•å…³é”®ç‚¹ä¿¡æ¯
                    if 'point_a' in pattern and 'point_b' in pattern and 'point_c' in pattern:
                        logger.debug(f"å…³é”®ç‚¹ - A: {pattern['point_a']['price']:.4f}, B: {pattern['point_b']['price']:.4f}, C: {pattern['point_c']['price']:.4f}")
                    
                    detected_patterns.append(pattern)
            
            # æ£€æµ‹EMAè¶‹åŠ¿ä¿¡å·
            ema_signal = self._detect_ema_trend_signal(symbol, timeframe)
            if ema_signal:
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°EMAè¶‹åŠ¿ä¿¡å·: {symbol} {timeframe} - {ema_signal['signal']} (èšåˆåº¦: {ema_signal['convergence']:.2f})")
                detected_patterns.append(ema_signal)
            
            # è¿”å›ä¼˜å…ˆçº§æœ€é«˜çš„å½¢æ€ï¼ˆåŒé¡¶/åŒåº•ä¼˜å…ˆäºEMAä¿¡å·ï¼‰
            if detected_patterns:
                # åŒé¡¶/åŒåº•å½¢æ€ä¼˜å…ˆçº§æ›´é«˜
                for pattern in detected_patterns:
                    if pattern.get('pattern_type') in ['double_top', 'double_bottom']:
                        return pattern
                # å¦‚æœæ²¡æœ‰åŒé¡¶/åŒåº•ï¼Œè¿”å›EMAä¿¡å·
                return detected_patterns[0]
            
            logger.debug(f"æœªæ£€æµ‹åˆ°å½¢æ€: {symbol} {timeframe}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æ {symbol} {timeframe} å½¢æ€å¤±è´¥: {str(e)}")
            raise
    
    def _should_send_signal(self, symbol: str, timeframe: str, pattern_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€ä¿¡å·ï¼ˆé˜²æ­¢é‡å¤ï¼‰"""
        current_time = time.time()
        
        # åˆ›å»ºä¿¡å·å”¯ä¸€æ ‡è¯†
        signal_key = f"{symbol}_{timeframe}_{pattern_type}"
        
        # æ£€æŸ¥ä¿¡å·æ˜¯å¦å·²ç»å‘é€è¿‡ï¼ˆ24å°æ—¶å†…ï¼‰
        if signal_key in self.sent_signals:
            last_sent_time = self.sent_signals[signal_key]
            time_diff = current_time - last_sent_time
            if time_diff < 86400:  # 24å°æ—¶ = 86400ç§’
                logger.info(f"â­ï¸ {signal_key} ä¿¡å·å·²åœ¨ {time_diff/3600:.1f} å°æ—¶å‰å‘é€è¿‡ï¼Œè·³è¿‡é‡å¤å‘é€")
                return False
        
        # æ£€æŸ¥å…¨å±€webhookå‘é€é—´éš”ï¼ˆ10ç§’ï¼‰
        if current_time - self.last_webhook_time < 10:
            return False
        
        # æ£€æŸ¥Telegramé…ç½®æ˜¯å¦æœ‰æ•ˆ
        telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
        telegram_channel = os.getenv('TELEGRAM_CHANNEL_ID')
        
        if not telegram_token or not telegram_channel:
            logger.debug(f"Telegramé…ç½®æ— æ•ˆï¼Œè·³è¿‡ä¿¡å·å‘é€ - {symbol} {pattern_type}")
            return False
        
        return True
    
    def _create_chart(self, symbol: str, timeframe: str, pattern_data: Dict) -> Optional[str]:
        """åˆ›å»ºKçº¿å›¾è¡¨ï¼ŒåŒ…å«æœ€æ–°æ”¶ç›˜Kçº¿åŠå·¦è¾¹55æ ¹Kçº¿ã€3æ¡EMAã€æˆäº¤é‡ã€ABCä¸‰ä¸ªç‚¹"""
        try:
            # è·å–Kçº¿æ•°æ®ï¼ˆ56æ ¹Kçº¿ï¼šæœ€æ–°1æ ¹+å·¦è¾¹55æ ¹ï¼‰
            klines = self._get_klines_data(symbol, timeframe, limit=56)
            if not klines or len(klines) < 56:
                logger.error(f"Kçº¿æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ - {symbol} {timeframe}")
                return None
            
            # è½¬æ¢ä¸ºDataFrameæ ¼å¼
            import pandas as pd
            df_data = []
            for kline in klines:
                df_data.append({
                    'timestamp': pd.to_datetime(int(kline[0]), unit='ms'),
                    'open': float(kline[1]),
                    'high': float(kline[2]),
                    'low': float(kline[3]),
                    'close': float(kline[4]),
                    'volume': float(kline[5])
                })
            
            df = pd.DataFrame(df_data)
            df.set_index('timestamp', inplace=True)
            
            # è®¡ç®—EMA
            df['ema21'] = df['close'].ewm(span=21).mean()
            df['ema55'] = df['close'].ewm(span=55).mean()
            df['ema144'] = df['close'].ewm(span=144).mean()
            
            # åˆ›å»ºå›¾è¡¨
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12), 
                                         gridspec_kw={'height_ratios': [3, 1]})
            
            # ç»˜åˆ¶Kçº¿å›¾
            from matplotlib.patches import Rectangle
            from matplotlib.lines import Line2D
            
            for i, (idx, row) in enumerate(df.iterrows()):
                # Kçº¿é¢œè‰²
                color = 'red' if row['close'] >= row['open'] else 'green'
                
                # ç»˜åˆ¶Kçº¿å®ä½“
                body_height = abs(row['close'] - row['open'])
                body_bottom = min(row['close'], row['open'])
                rect = Rectangle((i - 0.3, body_bottom), 0.6, body_height, 
                               facecolor=color, alpha=0.8)
                ax1.add_patch(rect)
                
                # ç»˜åˆ¶ä¸Šä¸‹å½±çº¿
                ax1.plot([i, i], [row['low'], row['high']], color=color, linewidth=1)
            
            # ç»˜åˆ¶EMAçº¿
            ax1.plot(range(len(df)), df['ema21'], color='blue', linewidth=2, label='EMA21', alpha=0.8)
            ax1.plot(range(len(df)), df['ema55'], color='orange', linewidth=2, label='EMA55', alpha=0.8)
            ax1.plot(range(len(df)), df['ema144'], color='purple', linewidth=2, label='EMA144', alpha=0.8)
            
            # æ ‡è®°ABCç‚¹
            if pattern_data.get('pattern_type') in ['åŒé¡¶', 'åŒåº•']:
                # è·å–ABCç‚¹ä¿¡æ¯
                a_point = pattern_data.get('a_point')
                b_point = pattern_data.get('b_point')
                c_point = pattern_data.get('c_point')
                
                if a_point and b_point and c_point:
                    # æ‰¾åˆ°å¯¹åº”çš„Kçº¿ç´¢å¼•
                    a_idx = self._find_kline_index_by_timestamp(klines, a_point['timestamp'])
                    b_idx = self._find_kline_index_by_timestamp(klines, b_point['timestamp'])
                    c_idx = self._find_kline_index_by_timestamp(klines, c_point['timestamp'])
                    
                    if a_idx >= 0:
                        ax1.scatter(a_idx, a_point['price'], color='red', s=100, marker='o', 
                                  label='Aç‚¹', zorder=5)
                        ax1.annotate('A', (a_idx, a_point['price']), xytext=(5, 5), 
                                   textcoords='offset points', fontsize=12, fontweight='bold')
                    
                    if b_idx >= 0:
                        ax1.scatter(b_idx, b_point['price'], color='blue', s=100, marker='o', 
                                  label='Bç‚¹', zorder=5)
                        ax1.annotate('B', (b_idx, b_point['price']), xytext=(5, 5), 
                                   textcoords='offset points', fontsize=12, fontweight='bold')
                    
                    if c_idx >= 0:
                        ax1.scatter(c_idx, c_point['price'], color='green', s=100, marker='o', 
                                  label='Cç‚¹', zorder=5)
                        ax1.annotate('C', (c_idx, c_point['price']), xytext=(5, 5), 
                                   textcoords='offset points', fontsize=12, fontweight='bold')
            
            # è®¾ç½®ä¸»å›¾æ ‡é¢˜å’Œæ ‡ç­¾
            ax1.set_title(f'{symbol} {timeframe} - {pattern_data.get("pattern_type", "ä¿¡å·")}', 
                         fontsize=16, fontweight='bold')
            ax1.set_ylabel('ä»·æ ¼', fontsize=12)
            ax1.legend(loc='upper left')
            ax1.grid(True, alpha=0.3)
            
            # ç»˜åˆ¶æˆäº¤é‡
            colors = ['red' if df.iloc[i]['close'] >= df.iloc[i]['open'] else 'green' 
                     for i in range(len(df))]
            ax2.bar(range(len(df)), df['volume'], color=colors, alpha=0.7)
            ax2.set_ylabel('æˆäº¤é‡', fontsize=12)
            ax2.set_xlabel('æ—¶é—´', fontsize=12)
            ax2.grid(True, alpha=0.3)
            
            # è®¾ç½®Xè½´æ ‡ç­¾ï¼ˆæ˜¾ç¤ºæ—¶é—´ï¼‰
            x_ticks = range(0, len(df), max(1, len(df)//10))  # æ˜¾ç¤º10ä¸ªæ—¶é—´ç‚¹
            x_labels = [df.index[i].strftime('%m-%d %H:%M') for i in x_ticks]
            ax1.set_xticks(x_ticks)
            ax1.set_xticklabels(x_labels, rotation=45)
            ax2.set_xticks(x_ticks)
            ax2.set_xticklabels(x_labels, rotation=45)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨åˆ°å†…å­˜
            img_buffer = io.BytesIO()
            plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
            img_buffer.seek(0)
            
            # è½¬æ¢ä¸ºbase64
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
            
            plt.close(fig)  # é‡Šæ”¾å†…å­˜
            
            logger.info(f"âœ… å›¾è¡¨åˆ›å»ºæˆåŠŸ - {symbol} {timeframe}")
            return img_base64
            
        except Exception as e:
            logger.error(f"âŒ å›¾è¡¨åˆ›å»ºå¤±è´¥ - {symbol} {timeframe}: {str(e)}")
            return None
    
    def _send_telegram_message(self, pattern_data: Dict, chart_base64: Optional[str] = None) -> bool:
        """å‘é€æ¶ˆæ¯å’Œå›¾ç‰‡åˆ°Telegram"""
        try:
            # æ£€æŸ¥Botå®ä¾‹æ˜¯å¦å­˜åœ¨
            if not self.telegram_bot:
                logger.warning("âŒ Telegram Botæœªé…ç½®ï¼Œè·³è¿‡å‘é€")
                logger.warning(f"  - Tokenå­˜åœ¨: {'æ˜¯' if self.telegram_token else 'å¦'}")
                logger.warning(f"  - Channel IDå­˜åœ¨: {'æ˜¯' if self.telegram_channel_id else 'å¦'}")
                return False
                
            # æ£€æŸ¥Channel ID
            if not self.telegram_channel_id:
                logger.error("âŒ Telegram Channel IDæœªé…ç½®")
                return False
                
            # æ£€æŸ¥å‘é€é—´éš”
            current_time = time.time()
            if current_time - self.last_telegram_time < self.telegram_send_interval:
                logger.info(f"â° Telegramå‘é€é—´éš”æœªåˆ°ï¼Œè·³è¿‡å‘é€ (é—´éš”: {current_time - self.last_telegram_time:.1f}s)")
                return False
            
            symbol = pattern_data.get('symbol', 'UNKNOWN')
            pattern_type = pattern_data.get('pattern_type', 'UNKNOWN')
            timeframe = pattern_data.get('timeframe', 'UNKNOWN')
            price = pattern_data.get('current_price', 0)
            
            logger.info(f"ğŸš€ å‡†å¤‡å‘é€Telegramæ¶ˆæ¯: {symbol} {pattern_type}")
            
            # æ„å»ºæ¶ˆæ¯æ–‡æœ¬
            message_lines = [
                f"ğŸš¨ {pattern_type} ä¿¡å·æ£€æµ‹",
                f"ğŸ“Š äº¤æ˜“å¯¹: {symbol}",
                f"â° æ—¶é—´æ¡†æ¶: {timeframe}",
                f"ğŸ’° å½“å‰ä»·æ ¼: {price}",
                f"ğŸ• æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            ]
            
            # æ·»åŠ ç‰¹å®šä¿¡å·ä¿¡æ¯
            if pattern_type in ['åŒé¡¶', 'åŒåº•']:
                if 'a_point' in pattern_data:
                    message_lines.append(f"ğŸ”´ Aç‚¹ä»·æ ¼: {pattern_data['a_point']['price']}")
                if 'b_point' in pattern_data:
                    message_lines.append(f"ğŸ”µ Bç‚¹ä»·æ ¼: {pattern_data['b_point']['price']}")
                if 'c_point' in pattern_data:
                    message_lines.append(f"ğŸŸ¢ Cç‚¹ä»·æ ¼: {pattern_data['c_point']['price']}")
                if 'quality_score' in pattern_data:
                    message_lines.append(f"â­ è´¨é‡åˆ†æ•°: {pattern_data['quality_score']:.2f}")
            elif 'EMA' in pattern_type or pattern_type in ['å¤šå¤´ä¿¡å·', 'ç©ºå¤´ä¿¡å·']:
                if 'ema21' in pattern_data:
                    message_lines.append(f"ğŸ“ˆ EMA21: {pattern_data['ema21']:.4f}")
                if 'ema55' in pattern_data:
                    message_lines.append(f"ğŸ“ˆ EMA55: {pattern_data['ema55']:.4f}")
                if 'ema144' in pattern_data:
                    message_lines.append(f"ğŸ“ˆ EMA144: {pattern_data['ema144']:.4f}")
                if 'convergence' in pattern_data:
                    message_lines.append(f"ğŸ”„ èšåˆåº¦: {pattern_data['convergence']:.2f}")
            
            message_text = '\n'.join(message_lines)
            logger.info(f"ğŸ“ æ¶ˆæ¯å†…å®¹å‡†å¤‡å®Œæˆï¼Œé•¿åº¦: {len(message_text)}")
            
            # å‘é€æ–‡æœ¬æ¶ˆæ¯ï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰
            logger.info(f"ğŸ“¤ æ­£åœ¨å‘é€æ–‡æœ¬æ¶ˆæ¯åˆ°é¢‘é“: {self.telegram_channel_id}")
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                response = loop.run_until_complete(self.telegram_bot.send_message(
                    chat_id=self.telegram_channel_id,
                    text=message_text,
                    parse_mode='HTML'
                ))
                logger.info(f"âœ… æ–‡æœ¬æ¶ˆæ¯å‘é€æˆåŠŸï¼Œæ¶ˆæ¯ID: {response.message_id}")
            finally:
                loop.close()
            
            # å¦‚æœæœ‰å›¾è¡¨ï¼Œå‘é€å›¾ç‰‡
            if chart_base64:
                try:
                    logger.info("ğŸ“Š å‡†å¤‡å‘é€å›¾è¡¨...")
                    img_data = base64.b64decode(chart_base64)
                    img_buffer = io.BytesIO(img_data)
                    img_buffer.name = f'{symbol}_{timeframe}_{pattern_type}.png'
                    
                    # ä½¿ç”¨æ–°çš„åŒæ­¥å‘é€æ–¹æ³•
                    success = self._send_photo_sync(
                        self.telegram_bot,
                        self.telegram_channel_id,
                        img_buffer,
                        f"{symbol} {pattern_type} å›¾è¡¨"
                    )
                    
                    if success:
                        logger.info("âœ… å›¾è¡¨å‘é€æˆåŠŸ")
                    else:
                        logger.error("âŒ å›¾è¡¨å‘é€å¤±è´¥")
                    
                except Exception as photo_error:
                    logger.error(f"âŒ å›¾è¡¨å‘é€å¤±è´¥: {str(photo_error)}")
                    # å›¾è¡¨å‘é€å¤±è´¥ä¸å½±å“æ•´ä½“æˆåŠŸçŠ¶æ€
            
            # æ›´æ–°å‘é€æ—¶é—´
            self.last_telegram_time = current_time
            
            logger.info(f"ğŸ‰ Telegramæ¶ˆæ¯å‘é€å®Œæˆ - {symbol} {pattern_type}")
            return True
            
        except TelegramError as e:
            logger.error(f"âŒ Telegram APIé”™è¯¯ - {symbol} {pattern_type}")
            logger.error(f"  - é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"  - Channel ID: {self.telegram_channel_id}")
            return False
        except Exception as e:
            logger.error(f"âŒ Telegramå‘é€å¼‚å¸¸ - {symbol} {pattern_type}")
            logger.error(f"  - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.error(f"  - å¼‚å¸¸ä¿¡æ¯: {str(e)}")
            logger.error(f"  - Channel ID: {self.telegram_channel_id}")
            return False
    
    def _send_photo_sync(self, bot: Bot, chat_id: str, photo_data: bytes, caption: str) -> bool:
        """åŒæ­¥å‘é€å›¾ç‰‡çš„è¾…åŠ©æ–¹æ³•"""
        try:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                # æ‰§è¡Œå¼‚æ­¥å‘é€
                result = loop.run_until_complete(
                    bot.send_photo(chat_id=chat_id, photo=photo_data, caption=caption)
                )
                return True
            finally:
                # ç¡®ä¿å¾ªç¯è¢«æ­£ç¡®å…³é—­
                loop.close()
                
        except Exception as e:
            logger.error(f"åŒæ­¥å‘é€å›¾ç‰‡å¤±è´¥: {e}")
            return False

    def _send_webhook(self, pattern_data: Dict) -> bool:
        """å‘é€ä¿¡å·åˆ°Telegramï¼ˆæ›¿ä»£åŸæœ‰webhookåŠŸèƒ½ï¼‰"""
        try:
            symbol = pattern_data.get('symbol', 'UNKNOWN')
            pattern_type = pattern_data.get('pattern_type', 'UNKNOWN')
            timeframe = pattern_data.get('timeframe', 'UNKNOWN')
            
            logger.info(f"å‡†å¤‡å‘é€Telegramæ¶ˆæ¯ - {symbol} {pattern_type} ({timeframe})")
            
            # åˆ›å»ºå›¾è¡¨
            chart_base64 = self._create_chart(symbol, timeframe, pattern_data)
            if not chart_base64:
                logger.warning(f"å›¾è¡¨åˆ›å»ºå¤±è´¥ï¼Œä»…å‘é€æ–‡æœ¬æ¶ˆæ¯ - {symbol} {pattern_type}")
            
            # å‘é€åˆ°Telegram
            success = self._send_telegram_message(pattern_data, chart_base64)
            
            if success:
                logger.info(f"âœ… Telegramæ¶ˆæ¯å‘é€æˆåŠŸ - {symbol} {pattern_type}")
            else:
                logger.error(f"âŒ Telegramæ¶ˆæ¯å‘é€å¤±è´¥ - {symbol} {pattern_type}")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ å‘é€Telegramæ¶ˆæ¯å¼‚å¸¸: {str(e)}")
            return False
    
    def _get_signal_price(self, pattern_data: Dict) -> float:
        """æ ¹æ®ä¿¡å·ç±»å‹è·å–å½“å‰ä»·æ ¼"""
        pattern_type = pattern_data.get('pattern_type', '')
        
        # åŒé¡¶/åŒåº•å½¢æ€ï¼šä¼˜å…ˆä½¿ç”¨Cç‚¹ä»·æ ¼ï¼Œå…¶æ¬¡Bç‚¹
        if pattern_type in ['åŒé¡¶', 'åŒåº•']:
            current_price = pattern_data.get('point_c', {}).get('price', 0)
            if not current_price:
                current_price = pattern_data.get('point_b', {}).get('price', 0)
            return current_price
        
        # EMAè¶‹åŠ¿ä¿¡å·ï¼šä½¿ç”¨å½“å‰ä»·æ ¼
        elif 'EMA' in pattern_type or pattern_type in ['å¤šå¤´ä¿¡å·', 'ç©ºå¤´ä¿¡å·']:
            return pattern_data.get('current_price', 0)
        
        # é»˜è®¤å¤„ç†
        return pattern_data.get('price', 0)
    
    def _add_double_pattern_data(self, webhook_data: Dict, pattern_data: Dict):
        """æ·»åŠ åŒé¡¶/åŒåº•å½¢æ€ç‰¹å®šæ•°æ®"""
        # æ·»åŠ å½¢æ€å…³é”®ç‚¹æ•°æ®
        webhook_data['pattern_points'] = {
            'A': pattern_data.get('point_a', {}),
            'B': pattern_data.get('point_b', {}),
            'C': pattern_data.get('point_c', {})
        }
        
        # æ·»åŠ Bç‚¹æ”¶ç›˜ä»·
        if 'point_b' in pattern_data:
            point_b = pattern_data['point_b']
            webhook_data['b_point_close_price'] = point_b.get('price', 0)
        else:
            webhook_data['b_point_close_price'] = None
            
        # æ·»åŠ å½¢æ€è¯†åˆ«ä¿¡æ¯
        webhook_data['pattern_identification'] = {
            'pattern_id': f"{pattern_data['symbol']}_{pattern_data['pattern_type']}_{pattern_data['timeframe']}_{int(datetime.now().timestamp())}",
            'detection_time': datetime.now().isoformat()
        }
    
    def _add_ema_signal_data(self, webhook_data: Dict, pattern_data: Dict):
        """æ·»åŠ EMAè¶‹åŠ¿ä¿¡å·ç‰¹å®šæ•°æ®"""
        # æ·»åŠ èšåˆåº¦æ•°å€¼
        webhook_data['convergence'] = pattern_data.get('convergence', 0)
        
        # æ·»åŠ EMAå€¼
        webhook_data['ema_values'] = {
            'ema21': pattern_data.get('ema21', 0),
            'ema55': pattern_data.get('ema55', 0),
            'ema144': pattern_data.get('ema144', 0)
        }
        
        # æ·»åŠ ä¿¡å·è¯†åˆ«ä¿¡æ¯
        webhook_data['signal_identification'] = {
            'convergence_ratio': pattern_data.get('convergence', 0),
            'alignment_state': pattern_data.get('alignment_state', 'unknown')
        }
    
    def _add_kline_pattern_data(self, webhook_data: Dict, pattern_data: Dict):
        """æ·»åŠ Kçº¿å½¢æ€ä¿¡æ¯"""
        kline_pattern = pattern_data.get('kline_pattern', {})
        webhook_data['kline_pattern'] = {
            'pattern': kline_pattern.get('pattern', 'none'),
            'strength': kline_pattern.get('strength', 0),
            'description': kline_pattern.get('description', 'æ— å½¢æ€')
        }
    
    def _analyze_all_pairs_concurrent(self, timeframe: str):
        """å¹¶å‘åˆ†ææ‰€æœ‰äº¤æ˜“å¯¹"""
        start_time = datetime.now()
        logger.info(f"========== å¼€å§‹å¹¶å‘åˆ†æ {timeframe} æ—¶é—´ç²’åº¦ ========== [{start_time.strftime('%Y-%m-%d %H:%M:%S')}]")
        
        total_pairs = len(self.monitored_pairs)
        success_count = 0
        failed_pairs = []
        patterns_found = []
        webhook_failures = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_concurrent_analysis) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_symbol = {
                executor.submit(self._analyze_pattern, symbol, timeframe): symbol 
                for symbol in self.monitored_pairs
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_symbol, timeout=self.analysis_timeout * 2):
                symbol = future_to_symbol[future]
                
                try:
                    pattern_result = future.result(timeout=self.analysis_timeout)
                    
                    if pattern_result:
                        pattern_type = pattern_result['pattern_type']
                        patterns_found.append(f"{symbol}_{pattern_type}")
                        logger.info(f"âœ“ {symbol} æ£€æµ‹åˆ°å½¢æ€: {pattern_type}")
                        
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€ä¿¡å·
                        if self._should_send_signal(symbol, timeframe, pattern_type):
                            try:
                                # å‘é€ä¿¡å·åˆ°Telegram
                                if self._send_webhook(pattern_result):
                                    # è®°å½•å·²å‘é€çš„ä¿¡å·
                                    signal_key = f"{symbol}_{timeframe}_{pattern_type}"
                                    self.sent_signals[signal_key] = time.time()
                                    logger.info(f"âœ… {symbol} {pattern_type} ä¿¡å·å·²å‘é€åˆ°Telegram")
                                else:
                                    logger.warning(f"âš ï¸ {symbol} {pattern_type} ä¿¡å·å‘é€å¤±è´¥")
                                    webhook_failures.append(f"{symbol}_{pattern_type}")
                            except Exception as e:
                                logger.error(f"âŒ {symbol} {pattern_type} ä¿¡å·å‘é€å¼‚å¸¸: {str(e)}")
                                webhook_failures.append(f"{symbol}_{pattern_type}")
                        else:
                            logger.info(f"â­ï¸ {symbol} {pattern_type} è·³è¿‡å‘é€ï¼ˆé—´éš”é™åˆ¶æˆ–å…¶ä»–æ¡ä»¶ï¼‰")
                    
                    success_count += 1
                    
                except Exception as e:
                    logger.error(f"åˆ†æ {symbol} å¤±è´¥: {str(e)}")
                    failed_pairs.append(symbol)
        
        # åˆ†æå®Œæˆç»Ÿè®¡
        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds()
        failed_count = len(failed_pairs)
        success_rate = (success_count / total_pairs) * 100 if total_pairs > 0 else 0
        
        logger.info(f"========== {timeframe} å¹¶å‘åˆ†æå®Œæˆ ==========")
        logger.info(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’ (å¹¶å‘å¤„ç†)")
        logger.info(f"æˆåŠŸç‡: {success_count}/{total_pairs} ({success_rate:.1f}%)")
        logger.info(f"å½¢æ€å‘ç°: {len(patterns_found)}ä¸ª")
        
        if failed_pairs:
            logger.warning(f"å¤±è´¥äº¤æ˜“å¯¹: {', '.join(failed_pairs)}")
        
        if webhook_failures:
            logger.warning(f"Webhookå¤±è´¥: {', '.join(webhook_failures)}")
        
        return {
            'total': total_pairs,
            'success': success_count,
            'failed': failed_count,
            'failed_pairs': failed_pairs,
            'patterns_found': patterns_found,
            'webhook_failures': webhook_failures,
            'success_rate': success_rate,
            'duration': total_duration
        }
    
    def _analyze_all_pairs_sequential(self, timeframe: str):
        """é¡ºåºåˆ†ææ‰€æœ‰äº¤æ˜“å¯¹ï¼Œæ¯ä¸ªä»£å¸APIè°ƒç”¨é—´éš”3ç§’"""
        start_time = datetime.now()
        logger.info(f"========== å¼€å§‹é¡ºåºåˆ†æ {timeframe} æ—¶é—´ç²’åº¦ (3ç§’é—´éš”) ========== [{start_time.strftime('%Y-%m-%d %H:%M:%S')}]")
        
        total_pairs = len(self.monitored_pairs)
        success_count = 0
        failed_pairs = []
        patterns_found = []
        webhook_failures = []
        
        # é¡ºåºå¤„ç†æ¯ä¸ªäº¤æ˜“å¯¹
        for i, symbol in enumerate(self.monitored_pairs):
            try:
                logger.info(f"æ­£åœ¨åˆ†æ {symbol} ({i+1}/{total_pairs})")
                
                # åœ¨åˆ†æå‰æ£€æŸ¥Aç‚¹æœ‰æ•ˆæ€§å¹¶æ›´æ–°ç¼“å­˜
                self._check_and_update_a_points(symbol, timeframe)
                
                # åˆ†æäº¤æ˜“å¯¹
                pattern_result = self._analyze_pattern(symbol, timeframe)
                
                if pattern_result:
                    pattern_type = pattern_result['pattern_type']
                    patterns_found.append(f"{symbol}_{pattern_type}")
                    logger.info(f"âœ“ {symbol} æ£€æµ‹åˆ°å½¢æ€: {pattern_type}")
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€ä¿¡å·
                    if self._should_send_signal(symbol, timeframe, pattern_type):
                        try:
                            # å‘é€Telegramä¿¡å·
                            success = self._send_webhook(pattern_result)
                            if success:
                                logger.info(f"âœ“ {symbol} {pattern_type} ä¿¡å·å·²å‘é€åˆ°Telegram")
                            else:
                                logger.warning(f"âš  {symbol} {pattern_type} ä¿¡å·å‘é€å¤±è´¥")
                        except Exception as e:
                            logger.error(f"âŒ {symbol} {pattern_type} ä¿¡å·å‘é€å¼‚å¸¸: {e}")
                    else:
                        logger.info(f"è·³è¿‡å‘é€ä¿¡å·: {symbol} {pattern_type} (é‡å¤æˆ–ä¸ç¬¦åˆå‘é€æ¡ä»¶)")
                
                success_count += 1
                
                # åœ¨å¤„ç†ä¸‹ä¸€ä¸ªä»£å¸å‰ç­‰å¾…3ç§’ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
                if i < total_pairs - 1:
                    logger.info(f"ç­‰å¾…3ç§’åå¤„ç†ä¸‹ä¸€ä¸ªä»£å¸...")
                    time.sleep(3)
                
            except Exception as e:
                logger.error(f"åˆ†æ {symbol} å¤±è´¥: {str(e)}")
                failed_pairs.append(symbol)
                
                # å³ä½¿å¤±è´¥ä¹Ÿè¦ç­‰å¾…3ç§’ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
                if i < total_pairs - 1:
                    logger.info(f"ç­‰å¾…3ç§’åå¤„ç†ä¸‹ä¸€ä¸ªä»£å¸...")
                    time.sleep(3)
        
        # åˆ†æå®Œæˆç»Ÿè®¡
        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds()
        failed_count = len(failed_pairs)
        success_rate = (success_count / total_pairs) * 100 if total_pairs > 0 else 0
        
        logger.info(f"========== {timeframe} é¡ºåºåˆ†æå®Œæˆ ==========")
        logger.info(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’ (é¡ºåºå¤„ç†ï¼Œ3ç§’é—´éš”)")
        logger.info(f"æˆåŠŸç‡: {success_count}/{total_pairs} ({success_rate:.1f}%)")
        logger.info(f"å½¢æ€å‘ç°: {len(patterns_found)}ä¸ª")
        
        if failed_pairs:
            logger.warning(f"å¤±è´¥äº¤æ˜“å¯¹: {', '.join(failed_pairs)}")
        
        if webhook_failures:
            logger.warning(f"Webhookå¤±è´¥: {', '.join(webhook_failures)}")
        
        return {
            'total': total_pairs,
            'success': success_count,
            'failed': failed_count,
            'failed_pairs': failed_pairs,
            'patterns_found': patterns_found,
            'webhook_failures': webhook_failures,
            'success_rate': success_rate,
            'duration': total_duration
        }
    
    def _monitor_timeframe(self, timeframe: str):
        """ç›‘æ§æŒ‡å®šæ—¶é—´ç²’åº¦"""
        logger.info(f"å¼€å§‹ç›‘æ§ {timeframe} æ—¶é—´ç²’åº¦")
        
        consecutive_errors = 0
        max_consecutive_errors = 8  # å¢åŠ å®¹é”™æ€§
        error_backoff_delays = [30, 60, 120, 300]
        
        # æ›´æ–°çº¿ç¨‹å¥åº·çŠ¶æ€
        if timeframe in self.thread_health:
            self.thread_health[timeframe]['last_activity'] = datetime.now()
        
        logger.info(f"[{timeframe}] ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾…é¦–æ¬¡è§¦å‘æ—¶é—´")
        
        # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªè§¦å‘æ—¶é—´çš„ç­‰å¾…æ—¶é—´
        def calculate_wait_time():
            current_time = datetime.now()
            if timeframe == '1h':
                # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªå°æ—¶01ç§’çš„ç­‰å¾…æ—¶é—´
                next_hour = current_time.replace(minute=0, second=1, microsecond=0) + timedelta(hours=1)
                wait_seconds = (next_hour - current_time).total_seconds()
                
                # å¦‚æœå½“å‰æ—¶é—´å·²ç»è¿‡äº†01ç§’ï¼Œç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªå°æ—¶çš„01ç§’
                if current_time.second > 1:
                    return wait_seconds
                # å¦‚æœå½“å‰æ—¶é—´åœ¨01ç§’ä¹‹å‰ï¼Œç­‰å¾…åˆ°å½“å‰å°æ—¶çš„01ç§’
                elif current_time.second < 1:
                    current_hour_trigger = current_time.replace(minute=0, second=1, microsecond=0)
                    wait_time = (current_hour_trigger - current_time).total_seconds()
                    # ç¡®ä¿è‡³å°‘ç­‰å¾…å‡ ç§’ï¼Œé¿å…å¯åŠ¨æ—¶ç«‹å³è§¦å‘
                    return max(wait_time, 5)
                else:
                    # æ­£å¥½æ˜¯01ç§’ï¼Œä½†ä¸ºäº†é¿å…å¯åŠ¨æ—¶ç«‹å³è§¦å‘ï¼Œç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªå°æ—¶
                    return wait_seconds
            return 60  # é»˜è®¤ç­‰å¾…1åˆ†é’Ÿ
        
        while self.running:
            try:
                # æ›´æ–°çº¿ç¨‹æ´»åŠ¨æ—¶é—´
                if timeframe in self.thread_health:
                    self.thread_health[timeframe]['last_activity'] = datetime.now()
                
                current_time = datetime.now()
                
                # è®¡ç®—ç­‰å¾…æ—¶é—´
                wait_time = calculate_wait_time()
                
                if wait_time > 0:
                    logger.info(f"[{timeframe}] ç­‰å¾… {wait_time:.1f} ç§’åˆ°ä¸‹ä¸€ä¸ªè§¦å‘æ—¶é—´ ({current_time.strftime('%H:%M:%S')})")
                    
                    # åˆ†æ®µç­‰å¾…ï¼Œæ¯30ç§’æ£€æŸ¥ä¸€æ¬¡è¿è¡ŒçŠ¶æ€
                    while wait_time > 0 and self.running:
                        sleep_duration = min(30, wait_time)
                        time.sleep(sleep_duration)
                        wait_time -= sleep_duration
                        
                        # æ›´æ–°çº¿ç¨‹æ´»åŠ¨æ—¶é—´
                        if timeframe in self.thread_health:
                            self.thread_health[timeframe]['last_activity'] = datetime.now()
                
                if not self.running:
                    break
                
                # åˆ°è¾¾è§¦å‘æ—¶é—´ï¼Œæ‰§è¡Œåˆ†æ
                current_time = datetime.now()
                analysis_key = f"{timeframe}_{current_time.strftime('%Y%m%d_%H')}"
                
                # é˜²é‡å¤åˆ†ææ£€æŸ¥
                if analysis_key not in self.last_analysis_time:
                    self.last_analysis_time[analysis_key] = current_time
                    logger.info(f"[{timeframe}] ğŸš€ å¼€å§‹æ‰§è¡Œåˆ†æ - {current_time.strftime('%H:%M:%S')}")
                    
                    try:
                        result = self._analyze_all_pairs_sequential(timeframe)
                        logger.info(f"[{timeframe}] âœ… åˆ†ææˆåŠŸ - è€—æ—¶: {result.get('duration', 0):.2f}ç§’")
                        
                        consecutive_errors = 0
                        self._update_system_health('healthy')
                        
                        # æ›´æ–°çº¿ç¨‹å¥åº·çŠ¶æ€
                        if timeframe in self.thread_health:
                            self.thread_health[timeframe]['status'] = 'running'
                            self.thread_health[timeframe]['error_count'] = 0
                            
                    except Exception as e:
                        logger.error(f"[{timeframe}] âŒ åˆ†æå¤±è´¥: {str(e)}")
                        consecutive_errors += 1
                        self._update_system_health('error', e)
                        
                        if timeframe in self.thread_health:
                            self.thread_health[timeframe]['status'] = 'error'
                            self.thread_health[timeframe]['error_count'] += 1
                else:
                    logger.info(f"[{timeframe}] â­ï¸ è·³è¿‡é‡å¤åˆ†æ - {analysis_key}")
                
                # é”™è¯¯æ¢å¤é€»è¾‘
                if consecutive_errors >= max_consecutive_errors:
                    delay_index = min(consecutive_errors - max_consecutive_errors, len(error_backoff_delays) - 1)
                    recovery_delay = error_backoff_delays[delay_index]
                    logger.warning(f"[{timeframe}] âš ï¸ è¿ç»­é”™è¯¯ {consecutive_errors} æ¬¡ï¼Œä¼‘çœ  {recovery_delay} ç§’")
                    time.sleep(recovery_delay)
                
                # æ¸…ç†è¿‡æœŸçš„åˆ†æè®°å½•ï¼ˆä¿ç•™æœ€è¿‘24å°æ—¶ï¼‰
                cutoff_time = current_time - timedelta(hours=24)
                expired_keys = [k for k, v in self.last_analysis_time.items() if v < cutoff_time]
                for key in expired_keys:
                    del self.last_analysis_time[key]
                
                if expired_keys:
                    logger.debug(f"[{timeframe}] æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸåˆ†æè®°å½•")
                
            except KeyboardInterrupt:
                logger.info(f"[{timeframe}] ç›‘æ§æ”¶åˆ°åœæ­¢ä¿¡å·")
                break
            except Exception as e:
                consecutive_errors += 1
                logger.error(f"[{timeframe}] ç›‘æ§å¼‚å¸¸: {str(e)}")
                self._update_system_health('error', e)
                
                if timeframe in self.thread_health:
                    self.thread_health[timeframe]['status'] = 'error'
                    self.thread_health[timeframe]['error_count'] += 1
                    self.thread_health[timeframe]['last_error'] = str(e)
                
                time.sleep(60)
        
        # çº¿ç¨‹ç»“æŸæ—¶æ›´æ–°çŠ¶æ€
        if timeframe in self.thread_health:
            self.thread_health[timeframe]['status'] = 'stopped'
            self.thread_health[timeframe]['last_activity'] = datetime.now()
        
        logger.info(f"{timeframe} ç›‘æ§çº¿ç¨‹å·²åœæ­¢")
    
    def _health_check_loop(self):
        """å¥åº·æ£€æŸ¥å¾ªç¯"""
        logger.info("å¯åŠ¨å¥åº·æ£€æŸ¥å¾ªç¯")
        
        while self.running:
            try:
                self._check_thread_health()
                
                # å†…å­˜ä½¿ç”¨æ£€æŸ¥
                process = psutil.Process()
                memory_usage = process.memory_info().rss
                
                if memory_usage > self.memory_limit:
                    logger.warning(f"å†…å­˜ä½¿ç”¨è¶…é™: {memory_usage / 1024 / 1024:.1f}MB")
                    # æ¸…ç†ç¼“å­˜
                    self.data_cache._cleanup_cache()
                    
                    # å¦‚æœå†…å­˜ä»ç„¶è¿‡é«˜ï¼Œæ¸…ç©ºæ‰€æœ‰ç¼“å­˜
                    if process.memory_info().rss > self.memory_limit:
                        logger.warning("å¼ºåˆ¶æ¸…ç†æ‰€æœ‰ç¼“å­˜")
                        self.data_cache.clear_all()
                        gc.collect()
                
                time.sleep(self.recovery_config['health_check_interval'])
                
            except Exception as e:
                logger.error(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {str(e)}")
                time.sleep(60)
        
        logger.info("å¥åº·æ£€æŸ¥å¾ªç¯ç»“æŸ")
    
    def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§ç³»ç»Ÿ"""
        logger.info("å¯åŠ¨åŠ å¯†è´§å¸å½¢æ€è¯†åˆ«ç›‘æ§ç³»ç»Ÿ")
        self.running = True
        self._update_system_health('starting')
        
        try:
            # ä¸ºæ¯ä¸ªæ—¶é—´ç²’åº¦å¯åŠ¨ç›‘æ§çº¿ç¨‹
            for timeframe in self.timeframes:
                thread = threading.Thread(
                    target=self._monitor_timeframe,
                    args=(timeframe,),
                    daemon=True,
                    name=f"Monitor-{timeframe}"
                )
                thread.start()
                
                self.monitor_threads[timeframe] = thread
                self.thread_health[timeframe] = {
                    'status': 'starting',
                    'last_activity': datetime.now(),
                    'error_count': 0,
                    'last_error': None
                }
                
                logger.info(f"å¯åŠ¨ {timeframe} ç›‘æ§çº¿ç¨‹")
            
            # å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹
            health_thread = threading.Thread(
                target=self._health_check_loop,
                daemon=True,
                name="HealthCheck"
            )
            health_thread.start()
            logger.info("å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹")
            
            self._update_system_health('running')
            
            # æ£€æµ‹è¿è¡Œç¯å¢ƒ
            is_railway = os.environ.get('RAILWAY_ENVIRONMENT') or os.environ.get('PORT')
            if not is_railway:
                # ä»…åœ¨æœ¬åœ°ç¯å¢ƒå¯åŠ¨Flaskåº”ç”¨
                logger.info("æœ¬åœ°ç¯å¢ƒæ£€æµ‹åˆ°ï¼Œå¯åŠ¨Flaskåº”ç”¨")
                app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000)), debug=False)
            else:
                logger.info("Railwayç¯å¢ƒæ£€æµ‹åˆ°ï¼Œç›‘æ§ç³»ç»Ÿå·²åœ¨åå°å¯åŠ¨ï¼ŒFlaskç”±gunicornç®¡ç†")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ç›‘æ§ç³»ç»Ÿå¤±è´¥: {str(e)}")
            self._update_system_health('error', e)
            raise
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        logger.info("åœæ­¢ç›‘æ§ç³»ç»Ÿ")
        self.running = False

# å…¨å±€ç›‘æ§å®ä¾‹
monitor = CryptoPatternMonitor()

# Flaskåº”ç”¨
app = Flask(__name__)

# åœ¨åº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨å¯åŠ¨ç›‘æ§ç³»ç»Ÿ
def start_monitoring_on_startup():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ç›‘æ§ç³»ç»Ÿ"""
    if not monitor.running:
        # æ— è®ºä»€ä¹ˆç¯å¢ƒï¼Œéƒ½å…ˆåˆå§‹åŒ–Aç‚¹ç¼“å­˜
        logger.info("å¼€å§‹åˆå§‹åŒ–æ‰€æœ‰ä»£å¸çš„Aç‚¹ç¼“å­˜...")
        try:
            monitor._initialize_all_pattern_cache()
            logger.info("æ‰€æœ‰ä»£å¸Aç‚¹ç¼“å­˜åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"Aç‚¹ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        is_railway = os.environ.get('RAILWAY_ENVIRONMENT') or os.environ.get('PORT')
        if is_railway:
            logger.info("Railwayç¯å¢ƒæ£€æµ‹åˆ°ï¼Œè‡ªåŠ¨å¯åŠ¨ç›‘æ§ç³»ç»Ÿ")
            # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ç›‘æ§ï¼ˆä¸å¯åŠ¨Flaskåº”ç”¨ï¼‰
            import threading
            def start_monitor_only():
                try:
                    # åŒé‡æ£€æŸ¥ï¼Œé˜²æ­¢é‡å¤å¯åŠ¨
                    if monitor.running:
                        logger.warning("ç›‘æ§ç³»ç»Ÿå·²åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
                        return
                        
                    monitor.running = True
                    monitor._update_system_health('starting')
                    
                    # å¯åŠ¨å„æ—¶é—´ç²’åº¦çš„ç›‘æ§çº¿ç¨‹
                    for timeframe in monitor.timeframes:
                        # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦å·²å­˜åœ¨
                        if timeframe in monitor.monitor_threads and monitor.monitor_threads[timeframe].is_alive():
                            logger.warning(f"{timeframe} ç›‘æ§çº¿ç¨‹å·²å­˜åœ¨ï¼Œè·³è¿‡å¯åŠ¨")
                            continue
                            
                        thread = threading.Thread(
                            target=monitor._monitor_timeframe,
                            args=(timeframe,),
                            daemon=True,
                            name=f"Monitor-{timeframe}"
                        )
                        thread.start()
                        
                        monitor.monitor_threads[timeframe] = thread
                        monitor.thread_health[timeframe] = {
                            'status': 'starting',
                            'last_activity': datetime.now(),
                            'error_count': 0,
                            'last_error': None
                        }
                        
                        logger.info(f"å¯åŠ¨ {timeframe} ç›‘æ§çº¿ç¨‹")
                    
                    # å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹
                    health_thread = threading.Thread(
                        target=monitor._health_check_loop,
                        daemon=True,
                        name="HealthCheck"
                    )
                    health_thread.start()
                    logger.info("å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹")
                    
                    monitor._update_system_health('running')
                    logger.info("ç›‘æ§ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼ˆRailwayç¯å¢ƒï¼‰")
                    
                except Exception as e:
                    logger.error(f"å¯åŠ¨ç›‘æ§ç³»ç»Ÿå¤±è´¥: {str(e)}")
                    monitor._update_system_health('error', e)
            
            monitor_thread = threading.Thread(target=start_monitor_only, daemon=True)
            monitor_thread.start()
        else:
            logger.info("æœ¬åœ°ç¯å¢ƒï¼ŒAç‚¹ç¼“å­˜å·²åˆå§‹åŒ–ï¼Œå¯æ‰‹åŠ¨å¯åŠ¨ç›‘æ§")

# ä½¿ç”¨åº”ç”¨ä¸Šä¸‹æ–‡å¯åŠ¨ç›‘æ§
with app.app_context():
    start_monitoring_on_startup()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    logger.info("è®¿é—®ä¸»é¡µ - è¿”å›ç³»ç»ŸçŠ¶æ€ä¿¡æ¯")
    
    try:
        memory_usage = psutil.Process().memory_info().rss / 1024 / 1024
        status_data = {
            'status': 'running' if monitor.running else 'stopped',
            'monitored_pairs': len(monitor.monitored_pairs),
            'timeframes': monitor.timeframes,
            'cache_stats': {
                'pattern_cache_size': len(monitor.pattern_cache),
                'kline_cache_size': len(monitor.data_cache.kline_cache),
                'atr_cache_size': len(monitor.data_cache.atr_cache)
            },
            'system_health': monitor.system_health['status'],
            'memory_usage_mb': memory_usage
        }
        
        logger.info(f"ç³»ç»ŸçŠ¶æ€: {status_data['status']}, å†…å­˜ä½¿ç”¨: {memory_usage:.2f}MB, ç›‘æ§å¯¹æ•°: {len(monitor.monitored_pairs)}")
        return jsonify(status_data)
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")
        return jsonify({
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/status')
def status():
    """ç³»ç»ŸçŠ¶æ€è¯¦æƒ…"""
    logger.info("è®¿é—®ç³»ç»ŸçŠ¶æ€è¯¦æƒ…é¡µé¢")
    current_time = datetime.now()
    
    # è®¡ç®—çº¿ç¨‹çŠ¶æ€ç»Ÿè®¡
    thread_stats = {'total': len(monitor.timeframes), 'healthy': 0, 'warning': 0, 'error': 0}
    thread_details = {}
    
    for timeframe, health in monitor.thread_health.items():
        if health['last_activity']:
            inactive_duration = (current_time - health['last_activity']).total_seconds()
            if inactive_duration > 900:
                status_level = 'error'
                thread_stats['error'] += 1
            elif health['error_count'] > 5:
                status_level = 'warning'
                thread_stats['warning'] += 1
            else:
                status_level = 'healthy'
                thread_stats['healthy'] += 1
        else:
            status_level = 'unknown'
        
        thread_details[timeframe] = {
            'status': status_level,
            'last_activity': health['last_activity'].isoformat() if health['last_activity'] else None,
            'error_count': health['error_count'],
            'last_error': str(health['last_error']) if health['last_error'] else None,
            'inactive_seconds': inactive_duration if health['last_activity'] else None
        }
    
    return jsonify({
        'system': {
            'running': monitor.running,
            'status': monitor.system_health['status'],
            'uptime_seconds': (current_time - monitor.system_health['start_time']).total_seconds(),
            'consecutive_errors': monitor.system_health['consecutive_errors'],
            'recovery_attempts': monitor.system_health['recovery_attempts'],
            'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024
        },
        'monitoring': {
            'monitored_pairs_count': len(monitor.monitored_pairs),
            'timeframes': monitor.timeframes,
            'thread_stats': thread_stats,
            'thread_details': thread_details
        },
        'cache': {
            'pattern_cache_size': len(monitor.pattern_cache),
            'kline_cache_size': len(monitor.data_cache.kline_cache),
            'atr_cache_size': len(monitor.data_cache.atr_cache),
            'cache_hit_ratio': 'N/A'  # å¯ä»¥å®ç°ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
        },
        'performance': {
            'concurrent_analysis': monitor.max_concurrent_analysis,
            'analysis_timeout': monitor.analysis_timeout
        },
        'timestamp': current_time.isoformat()
    })

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    logger.info("è®¿é—®å¥åº·æ£€æŸ¥ç«¯ç‚¹")
    current_time = datetime.now()
    system_status = monitor.system_health['status']
    
    # æ£€æŸ¥çº¿ç¨‹å¥åº·çŠ¶æ€
    unhealthy_threads = 0
    total_threads = len(monitor.timeframes)
    
    for timeframe, health in monitor.thread_health.items():
        if health['last_activity']:
            inactive_duration = (current_time - health['last_activity']).total_seconds()
            if inactive_duration > 900 or health['error_count'] > 10:
                unhealthy_threads += 1
    
    # ç¡®å®šHTTPçŠ¶æ€ç 
    if system_status == 'critical' or unhealthy_threads > total_threads / 2:
        http_status = 503
        overall_status = 'unhealthy'
    elif system_status == 'degraded' or unhealthy_threads > 0:
        http_status = 200
        overall_status = 'degraded'
    else:
        http_status = 200
        overall_status = 'healthy'
    
    response_data = {
        'status': overall_status,
        'system_status': system_status,
        'running': monitor.running,
        'threads': {
            'total': total_threads,
            'healthy': total_threads - unhealthy_threads,
            'unhealthy': unhealthy_threads
        },
        'uptime_seconds': (current_time - monitor.system_health['start_time']).total_seconds(),
        'consecutive_errors': monitor.system_health['consecutive_errors'],
        'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024,
        'environment': 'railway' if (os.environ.get('RAILWAY_ENVIRONMENT') or os.environ.get('PORT')) else 'local',
        'timestamp': current_time.isoformat()
    }
    
    logger.info(f"å¥åº·æ£€æŸ¥å®Œæˆ - çŠ¶æ€: {overall_status}, ç³»ç»ŸçŠ¶æ€: {system_status}, å¥åº·çº¿ç¨‹: {total_threads - unhealthy_threads}/{total_threads}")
    
    return jsonify(response_data), http_status

@app.route('/telegram/test')
def test_telegram():
    """æµ‹è¯•Telegramé…ç½®å’Œè¿æ¥"""
    try:
        result = {
            'status': 'success',
            'config': {
                'token_exists': bool(monitor.telegram_token),
                'token_length': len(monitor.telegram_token) if monitor.telegram_token else 0,
                'channel_id_exists': bool(monitor.telegram_channel_id),
                'channel_id': monitor.telegram_channel_id,
                'bot_instance_exists': monitor.telegram_bot is not None
            },
            'tests': {}
        }
        
        # æµ‹è¯•ç¯å¢ƒå˜é‡
        telegram_env_vars = {k: v for k, v in os.environ.items() if 'TELEGRAM' in k.upper()}
        result['config']['env_vars'] = list(telegram_env_vars.keys())
        
        # æµ‹è¯•Botè¿æ¥ï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰
        if monitor.telegram_bot:
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    bot_info = loop.run_until_complete(monitor.telegram_bot.get_me())
                    result['tests']['bot_connection'] = {
                        'status': 'success',
                        'bot_username': bot_info.username,
                        'bot_id': bot_info.id,
                        'bot_name': bot_info.first_name
                    }
                finally:
                    loop.close()
            except Exception as e:
                result['tests']['bot_connection'] = {
                    'status': 'error',
                    'error': str(e)
                }
        else:
            result['tests']['bot_connection'] = {
                'status': 'error',
                'error': 'Bot instance not created'
            }
        
        # æµ‹è¯•å‘é€æ¶ˆæ¯ï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰
        if monitor.telegram_bot and monitor.telegram_channel_id:
            try:
                test_message = f"ğŸ§ª Telegramè¿æ¥æµ‹è¯• - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                msg_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(msg_loop)
                try:
                    response = msg_loop.run_until_complete(monitor.telegram_bot.send_message(
                        chat_id=monitor.telegram_channel_id,
                        text=test_message
                    ))
                    result['tests']['message_send'] = {
                        'status': 'success',
                        'message_id': response.message_id,
                        'chat_id': response.chat.id
                    }
                finally:
                    msg_loop.close()
            except Exception as e:
                result['tests']['message_send'] = {
                    'status': 'error',
                    'error': str(e)
                }
        else:
            result['tests']['message_send'] = {
                'status': 'skipped',
                'reason': 'Bot or channel ID not configured'
            }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/cache/clear')
def clear_cache():
    """æ¸…ç†ç¼“å­˜ç«¯ç‚¹"""
    logger.info("è®¿é—®ç¼“å­˜æ¸…ç†æ¥å£")
    try:
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # è®°å½•æ¸…ç†å‰çš„ç¼“å­˜çŠ¶æ€
        before_kline = len(monitor.data_cache.kline_cache)
        before_atr = len(monitor.data_cache.atr_cache)
        before_pattern = len(monitor.pattern_cache)
        
        logger.info(f"æ¸…ç†å‰ç¼“å­˜çŠ¶æ€ - Kçº¿ç¼“å­˜: {before_kline}, ATRç¼“å­˜: {before_atr}, æ¨¡å¼ç¼“å­˜: {before_pattern}")
        logger.info(f"æ¸…ç†å‰å†…å­˜ä½¿ç”¨: {initial_memory:.2f} MB")
        
        monitor.data_cache.clear_all()
        monitor.pattern_cache.clear()
        gc.collect()
        
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_freed = initial_memory - final_memory
        
        logger.info(f"ç¼“å­˜æ¸…ç†å®Œæˆ - é‡Šæ”¾å†…å­˜: {memory_freed:.2f} MB, å½“å‰å†…å­˜: {final_memory:.2f} MB")
        
        return jsonify({
            'success': True,
            'message': 'Cache cleared successfully',
            'memory_freed_mb': memory_freed,
            'current_memory_mb': final_memory,
            'cleared_items': {
                'kline_cache': before_kline,
                'atr_cache': before_atr,
                'pattern_cache': before_pattern
            }
        })
    except Exception as e:
        logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def create_app():
    """åˆ›å»ºFlaskåº”ç”¨"""
    return app

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("åˆå§‹åŒ–åŠ å¯†è´§å¸å½¢æ€è¯†åˆ«ç›‘æ§ç³»ç»Ÿ")
        # æ£€æŸ¥æ˜¯å¦ä¸ºRailwayç¯å¢ƒï¼Œå¦‚æœæ˜¯åˆ™ä¸é‡å¤å¯åŠ¨ç›‘æ§ï¼ˆå·²åœ¨start_monitoring_on_startupä¸­å¯åŠ¨ï¼‰
        is_railway = os.environ.get('RAILWAY_ENVIRONMENT') or os.environ.get('PORT')
        if not is_railway:
            logger.info("æœ¬åœ°ç¯å¢ƒï¼Œå¯åŠ¨ç›‘æ§ç³»ç»Ÿ")
            monitor.start_monitoring()
        else:
            logger.info("Railwayç¯å¢ƒï¼Œç›‘æ§ç³»ç»Ÿå·²åœ¨åº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨å¯åŠ¨")
            # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
            import time
            while True:
                time.sleep(60)
    except KeyboardInterrupt:
        logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·")
        monitor.stop_monitoring()
    except Exception as e:
        logger.error(f"ç³»ç»Ÿè¿è¡Œå¼‚å¸¸: {str(e)}")
        monitor.stop_monitoring()

if __name__ == '__main__':
    main()
